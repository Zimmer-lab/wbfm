{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DLC for WBFM analysis: chip setup\n",
    "\n",
    "This workflow requires three preparation steps:\n",
    "\n",
    "- Preprocessing from .stk to a large ome.tiff file, currently using FIJI\n",
    "- Conversion of a slice to .avi, currently using Python\n",
    "- Manual labeling with the DLC gui, on a local machine\n",
    "    - Then the created project should be copied to the cluster where this training is run\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Load locally-labeled project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLClight=True\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "%env DLClight=True\n",
    "import deeplabcut\n",
    "import os\n",
    "from DLC_for_WBFM.utils.training_data.training_settings_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Copied from the local machine\n",
    "project_folder = r\"C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\"\n",
    "# project_folder = '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12'\n",
    "path_config_file = os.path.join(project_folder, 'config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF ON CLUSTER: Update the path files to be Unix, not Windows\n",
    "\n",
    "Notes on how to do this programmatically:\n",
    "https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/maDLC_AdvUserGuide.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already on Windows machine; no updating required\n"
     ]
    }
   ],
   "source": [
    "if os.name is not 'nt':\n",
    "    video_fname = os.path.join(project_folder, 'videos/27082020_trial2_HEAD_500frames_mcherry_slice8.avi')\n",
    "    # video_fname = '/users/charles.fieseler/shared_projects/wbfm/dat/immobilized_wbfm_hardware/27082020_trial2_dual1_HEAD_500frames_mcherry_slice8.avi'\n",
    "    edits = {'project_path': project_folder,\n",
    "            'video_sets': {video_fname : {'crop':[0, 332, 0, 132]}}}\n",
    "\n",
    "    deeplabcut.auxiliaryfunctions.edit_config(path_config_file, edits);\n",
    "else:\n",
    "    print(\"Already on Windows machine; no updating required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "\n",
    "This function generates the training data information for network training based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles if they want to benchmark the performance (typcailly, 1 is what you will set, so you pass nothing!). \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**. For most all use cases we have seen, the defaults are perfectly fine.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\training-datasets\\iteration-0\\UnaugmentedDataSet_wbfm_3dOct21  already exists!\n",
      "C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\dlc-models\\iteration-0\\wbfm_3dOct21-trainset95shuffle1  already exists!\n",
      "C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\dlc-models\\iteration-0\\wbfm_3dOct21-trainset95shuffle1/train  already exists!\n",
      "C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\dlc-models\\iteration-0\\wbfm_3dOct21-trainset95shuffle1/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([ 1, 21, 26,  4, 24,  8,  3, 11, 20, 10,  6, 17, 29,  5, 14,  2, 18,\n",
       "          13, 28, 15,  9, 23,  7, 27, 16,  0, 12, 19]),\n",
       "   array([22, 25])))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file, augmenter_type='imgaug')\n",
    "#remember, there are several networks you can pick, the default is resnet-50!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished updating training config file\n"
     ]
    }
   ],
   "source": [
    "# Update the training files\n",
    "update_pose_cfg(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training:\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['neuron0', 'neuron1', 'neuron2'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_wbfm_3dOct21\\\\wbfm_3d_Charlie95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\charles.fieseler\\\\Anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_wbfm_3dOct21\\\\Documentation_data-wbfm_3d_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.02, 1000], [0.005, 5000], [0.001, 20000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\charles.fieseler\\\\Documents\\\\Current_work\\\\DLC_for_WBFM\\\\DLC_Projects\\\\wbfm_3d-Charlie-2020-10-21',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'rotate_max_deg_abs': 180,\n",
      " 'rotation': 180,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\charles.fieseler\\\\Documents\\\\Current_work\\\\DLC_for_WBFM\\\\DLC_Projects\\\\wbfm_3d-Charlie-2020-10-21\\\\dlc-models\\\\iteration-0\\\\wbfm_3dOct21-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with imgaug pose-dataset loader.\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "WARNING:tensorflow:From C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "WARNING:tensorflow:From C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt\n",
      "Display_iters overwritten as 100\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\charles.fieseler\\\\Documents\\\\Current_work\\\\DLC_for_WBFM\\\\DLC_Projects\\\\wbfm_3d-Charlie-2020-10-21\\\\dlc-models\\\\iteration-0\\\\wbfm_3dOct21-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2]], 'all_joints_names': ['neuron0', 'neuron1', 'neuron2'], 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_wbfm_3dOct21\\\\wbfm_3d_Charlie95shuffle1.mat', 'display_iters': 1000, 'init_weights': 'C:\\\\Users\\\\charles.fieseler\\\\Anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_wbfm_3dOct21\\\\Documentation_data-wbfm_3d_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.02, 1000], [0.005, 5000], [0.001, 20000]], 'net_type': 'resnet_50', 'num_joints': 3, 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\charles.fieseler\\\\Documents\\\\Current_work\\\\DLC_for_WBFM\\\\DLC_Projects\\\\wbfm_3d-Charlie-2020-10-21', 'rotate_max_deg_abs': 180, 'rotation': 180, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'output_stride': 16, 'deconvolutionstride': 2}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 100 loss: 0.0482 lr: 0.02\n",
      "iteration: 200 loss: 0.0222 lr: 0.02\n",
      "iteration: 300 loss: 0.0184 lr: 0.02\n",
      "iteration: 400 loss: 0.0150 lr: 0.02\n",
      "iteration: 500 loss: 0.0132 lr: 0.02\n",
      "iteration: 600 loss: 0.0126 lr: 0.02\n",
      "iteration: 700 loss: 0.0107 lr: 0.02\n",
      "iteration: 800 loss: 0.0105 lr: 0.02\n",
      "iteration: 900 loss: 0.0091 lr: 0.02\n",
      "iteration: 1000 loss: 0.0080 lr: 0.02\n",
      "iteration: 1100 loss: 0.0076 lr: 0.005\n",
      "iteration: 1200 loss: 0.0069 lr: 0.005\n",
      "iteration: 1300 loss: 0.0067 lr: 0.005\n",
      "iteration: 1400 loss: 0.0072 lr: 0.005\n",
      "iteration: 1500 loss: 0.0068 lr: 0.005\n",
      "iteration: 1600 loss: 0.0068 lr: 0.005\n",
      "iteration: 1700 loss: 0.0065 lr: 0.005\n",
      "iteration: 1800 loss: 0.0069 lr: 0.005\n",
      "iteration: 1900 loss: 0.0061 lr: 0.005\n",
      "iteration: 2000 loss: 0.0065 lr: 0.005\n",
      "iteration: 2100 loss: 0.0063 lr: 0.005\n",
      "iteration: 2200 loss: 0.0061 lr: 0.005\n",
      "iteration: 2300 loss: 0.0066 lr: 0.005\n",
      "iteration: 2400 loss: 0.0059 lr: 0.005\n",
      "iteration: 2500 loss: 0.0061 lr: 0.005\n",
      "iteration: 2600 loss: 0.0059 lr: 0.005\n",
      "iteration: 2700 loss: 0.0056 lr: 0.005\n",
      "iteration: 2800 loss: 0.0060 lr: 0.005\n",
      "iteration: 2900 loss: 0.0058 lr: 0.005\n",
      "iteration: 3000 loss: 0.0055 lr: 0.005\n",
      "iteration: 3100 loss: 0.0055 lr: 0.005\n",
      "iteration: 3200 loss: 0.0058 lr: 0.005\n",
      "iteration: 3300 loss: 0.0053 lr: 0.005\n",
      "iteration: 3400 loss: 0.0057 lr: 0.005\n",
      "iteration: 3500 loss: 0.0054 lr: 0.005\n",
      "iteration: 3600 loss: 0.0054 lr: 0.005\n",
      "iteration: 3700 loss: 0.0057 lr: 0.005\n",
      "iteration: 3800 loss: 0.0051 lr: 0.005\n",
      "iteration: 3900 loss: 0.0055 lr: 0.005\n",
      "iteration: 4000 loss: 0.0052 lr: 0.005\n",
      "iteration: 4100 loss: 0.0052 lr: 0.005\n",
      "iteration: 4200 loss: 0.0052 lr: 0.005\n",
      "iteration: 4300 loss: 0.0052 lr: 0.005\n",
      "iteration: 4400 loss: 0.0050 lr: 0.005\n",
      "iteration: 4500 loss: 0.0047 lr: 0.005\n",
      "iteration: 4600 loss: 0.0048 lr: 0.005\n",
      "iteration: 4700 loss: 0.0052 lr: 0.005\n",
      "iteration: 4800 loss: 0.0050 lr: 0.005\n",
      "iteration: 4900 loss: 0.0050 lr: 0.005\n",
      "iteration: 5000 loss: 0.0047 lr: 0.005\n",
      "iteration: 5100 loss: 0.0044 lr: 0.001\n",
      "iteration: 5200 loss: 0.0046 lr: 0.001\n",
      "iteration: 5300 loss: 0.0045 lr: 0.001\n",
      "iteration: 5400 loss: 0.0047 lr: 0.001\n",
      "iteration: 5500 loss: 0.0047 lr: 0.001\n",
      "iteration: 5600 loss: 0.0046 lr: 0.001\n",
      "iteration: 5700 loss: 0.0043 lr: 0.001\n",
      "iteration: 5800 loss: 0.0046 lr: 0.001\n",
      "iteration: 5900 loss: 0.0046 lr: 0.001\n",
      "iteration: 6000 loss: 0.0045 lr: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 6100 loss: 0.0044 lr: 0.001\n",
      "iteration: 6200 loss: 0.0045 lr: 0.001\n",
      "iteration: 6300 loss: 0.0045 lr: 0.001\n",
      "iteration: 6400 loss: 0.0042 lr: 0.001\n",
      "iteration: 6500 loss: 0.0044 lr: 0.001\n",
      "iteration: 6600 loss: 0.0045 lr: 0.001\n",
      "iteration: 6700 loss: 0.0045 lr: 0.001\n",
      "iteration: 6800 loss: 0.0044 lr: 0.001\n",
      "iteration: 6900 loss: 0.0043 lr: 0.001\n",
      "iteration: 7000 loss: 0.0045 lr: 0.001\n",
      "iteration: 7100 loss: 0.0044 lr: 0.001\n",
      "iteration: 7200 loss: 0.0045 lr: 0.001\n",
      "iteration: 7300 loss: 0.0045 lr: 0.001\n",
      "iteration: 7400 loss: 0.0043 lr: 0.001\n",
      "iteration: 7500 loss: 0.0043 lr: 0.001\n",
      "iteration: 7600 loss: 0.0040 lr: 0.001\n",
      "iteration: 7700 loss: 0.0041 lr: 0.001\n",
      "iteration: 7800 loss: 0.0044 lr: 0.001\n",
      "iteration: 7900 loss: 0.0046 lr: 0.001\n",
      "iteration: 8000 loss: 0.0042 lr: 0.001\n",
      "iteration: 8100 loss: 0.0043 lr: 0.001\n",
      "iteration: 8200 loss: 0.0041 lr: 0.001\n",
      "iteration: 8300 loss: 0.0041 lr: 0.001\n",
      "iteration: 8400 loss: 0.0042 lr: 0.001\n",
      "iteration: 8500 loss: 0.0043 lr: 0.001\n",
      "iteration: 8600 loss: 0.0042 lr: 0.001\n",
      "iteration: 8700 loss: 0.0040 lr: 0.001\n",
      "iteration: 8800 loss: 0.0044 lr: 0.001\n",
      "iteration: 8900 loss: 0.0043 lr: 0.001\n",
      "iteration: 9000 loss: 0.0044 lr: 0.001\n",
      "iteration: 9100 loss: 0.0044 lr: 0.001\n",
      "iteration: 9200 loss: 0.0043 lr: 0.001\n",
      "iteration: 9300 loss: 0.0042 lr: 0.001\n",
      "iteration: 9400 loss: 0.0042 lr: 0.001\n",
      "iteration: 9500 loss: 0.0045 lr: 0.001\n",
      "iteration: 9600 loss: 0.0042 lr: 0.001\n",
      "iteration: 9700 loss: 0.0044 lr: 0.001\n",
      "iteration: 9800 loss: 0.0041 lr: 0.001\n",
      "iteration: 9900 loss: 0.0045 lr: 0.001\n",
      "iteration: 10000 loss: 0.0043 lr: 0.001\n",
      "iteration: 10100 loss: 0.0043 lr: 0.001\n",
      "iteration: 10200 loss: 0.0043 lr: 0.001\n",
      "iteration: 10300 loss: 0.0040 lr: 0.001\n",
      "iteration: 10400 loss: 0.0040 lr: 0.001\n",
      "iteration: 10500 loss: 0.0041 lr: 0.001\n",
      "iteration: 10600 loss: 0.0040 lr: 0.001\n",
      "iteration: 10700 loss: 0.0042 lr: 0.001\n",
      "iteration: 10800 loss: 0.0041 lr: 0.001\n",
      "iteration: 10900 loss: 0.0043 lr: 0.001\n",
      "iteration: 11000 loss: 0.0044 lr: 0.001\n",
      "iteration: 11100 loss: 0.0043 lr: 0.001\n",
      "iteration: 11200 loss: 0.0040 lr: 0.001\n",
      "iteration: 11300 loss: 0.0039 lr: 0.001\n",
      "iteration: 11400 loss: 0.0042 lr: 0.001\n",
      "iteration: 11500 loss: 0.0043 lr: 0.001\n",
      "iteration: 11600 loss: 0.0039 lr: 0.001\n",
      "iteration: 11700 loss: 0.0042 lr: 0.001\n",
      "iteration: 11800 loss: 0.0040 lr: 0.001\n",
      "iteration: 11900 loss: 0.0041 lr: 0.001\n",
      "iteration: 12000 loss: 0.0039 lr: 0.001\n",
      "iteration: 12100 loss: 0.0040 lr: 0.001\n",
      "iteration: 12200 loss: 0.0040 lr: 0.001\n",
      "iteration: 12300 loss: 0.0043 lr: 0.001\n",
      "iteration: 12400 loss: 0.0038 lr: 0.001\n",
      "iteration: 12500 loss: 0.0040 lr: 0.001\n",
      "iteration: 12600 loss: 0.0040 lr: 0.001\n",
      "iteration: 12700 loss: 0.0043 lr: 0.001\n",
      "iteration: 12800 loss: 0.0040 lr: 0.001\n",
      "iteration: 12900 loss: 0.0040 lr: 0.001\n",
      "iteration: 13000 loss: 0.0036 lr: 0.001\n",
      "iteration: 13100 loss: 0.0041 lr: 0.001\n",
      "iteration: 13200 loss: 0.0039 lr: 0.001\n",
      "iteration: 13300 loss: 0.0039 lr: 0.001\n",
      "iteration: 13400 loss: 0.0037 lr: 0.001\n",
      "iteration: 13500 loss: 0.0040 lr: 0.001\n",
      "iteration: 13600 loss: 0.0040 lr: 0.001\n",
      "iteration: 13700 loss: 0.0038 lr: 0.001\n",
      "iteration: 13800 loss: 0.0039 lr: 0.001\n",
      "iteration: 13900 loss: 0.0040 lr: 0.001\n",
      "iteration: 14000 loss: 0.0041 lr: 0.001\n",
      "iteration: 14100 loss: 0.0038 lr: 0.001\n",
      "iteration: 14200 loss: 0.0038 lr: 0.001\n",
      "iteration: 14300 loss: 0.0040 lr: 0.001\n",
      "iteration: 14400 loss: 0.0037 lr: 0.001\n",
      "iteration: 14500 loss: 0.0038 lr: 0.001\n",
      "iteration: 14600 loss: 0.0036 lr: 0.001\n",
      "iteration: 14700 loss: 0.0039 lr: 0.001\n",
      "iteration: 14800 loss: 0.0035 lr: 0.001\n",
      "iteration: 14900 loss: 0.0039 lr: 0.001\n",
      "iteration: 15000 loss: 0.0037 lr: 0.001\n",
      "iteration: 15100 loss: 0.0040 lr: 0.001\n",
      "iteration: 15200 loss: 0.0038 lr: 0.001\n",
      "iteration: 15300 loss: 0.0038 lr: 0.001\n",
      "iteration: 15400 loss: 0.0035 lr: 0.001\n",
      "iteration: 15500 loss: 0.0036 lr: 0.001\n",
      "iteration: 15600 loss: 0.0038 lr: 0.001\n",
      "iteration: 15700 loss: 0.0037 lr: 0.001\n",
      "iteration: 15800 loss: 0.0041 lr: 0.001\n",
      "iteration: 15900 loss: 0.0038 lr: 0.001\n",
      "iteration: 16000 loss: 0.0038 lr: 0.001\n",
      "iteration: 16100 loss: 0.0040 lr: 0.001\n",
      "iteration: 16200 loss: 0.0039 lr: 0.001\n",
      "iteration: 16300 loss: 0.0037 lr: 0.001\n",
      "iteration: 16400 loss: 0.0039 lr: 0.001\n",
      "iteration: 16500 loss: 0.0037 lr: 0.001\n",
      "iteration: 16600 loss: 0.0040 lr: 0.001\n",
      "iteration: 16700 loss: 0.0036 lr: 0.001\n",
      "iteration: 16800 loss: 0.0036 lr: 0.001\n",
      "iteration: 16900 loss: 0.0039 lr: 0.001\n",
      "iteration: 17000 loss: 0.0036 lr: 0.001\n",
      "iteration: 17100 loss: 0.0036 lr: 0.001\n",
      "iteration: 17200 loss: 0.0040 lr: 0.001\n",
      "iteration: 17300 loss: 0.0037 lr: 0.001\n",
      "iteration: 17400 loss: 0.0039 lr: 0.001\n",
      "iteration: 17500 loss: 0.0038 lr: 0.001\n",
      "iteration: 17600 loss: 0.0037 lr: 0.001\n",
      "iteration: 17700 loss: 0.0038 lr: 0.001\n",
      "iteration: 17800 loss: 0.0036 lr: 0.001\n",
      "iteration: 17900 loss: 0.0038 lr: 0.001\n",
      "iteration: 18000 loss: 0.0035 lr: 0.001\n",
      "iteration: 18100 loss: 0.0036 lr: 0.001\n",
      "iteration: 18200 loss: 0.0038 lr: 0.001\n",
      "iteration: 18300 loss: 0.0035 lr: 0.001\n",
      "iteration: 18400 loss: 0.0035 lr: 0.001\n",
      "iteration: 18500 loss: 0.0036 lr: 0.001\n",
      "iteration: 18600 loss: 0.0034 lr: 0.001\n",
      "iteration: 18700 loss: 0.0035 lr: 0.001\n",
      "iteration: 18800 loss: 0.0036 lr: 0.001\n",
      "iteration: 18900 loss: 0.0037 lr: 0.001\n",
      "iteration: 19000 loss: 0.0037 lr: 0.001\n",
      "iteration: 19100 loss: 0.0032 lr: 0.001\n",
      "iteration: 19200 loss: 0.0035 lr: 0.001\n",
      "iteration: 19300 loss: 0.0035 lr: 0.001\n",
      "iteration: 19400 loss: 0.0035 lr: 0.001\n",
      "iteration: 19500 loss: 0.0036 lr: 0.001\n",
      "iteration: 19600 loss: 0.0034 lr: 0.001\n",
      "iteration: 19700 loss: 0.0037 lr: 0.001\n",
      "iteration: 19800 loss: 0.0035 lr: 0.001\n",
      "iteration: 19900 loss: 0.0034 lr: 0.001\n",
      "iteration: 20000 loss: 0.0036 lr: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 81, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:67) ]]\n",
      "\n",
      "Caused by op 'fifo_queue_enqueue', defined at:\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2922, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-56b077e42ab3>\", line 1, in <module>\n",
      "    deeplabcut.train_network(path_config_file, displayiters=100, saveiters=1000)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 132, in train_network\n",
      "    train(str(poseconfigfile),displayiters,saveiters,maxiters,max_to_keep=max_snapshots_to_keep,keepdeconvweights=keepdeconvweights,allow_growth=allow_growth) #pass on path and file name for pose_cfg.yaml!\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 118, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 67, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 345, in enqueue\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4158, in queue_enqueue_v2\n",
      "    timeout_ms=timeout_ms, name=name)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:67) ]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file, displayiters=100, saveiters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['neuron0', 'neuron1', 'neuron2'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_wbfm_3dOct21\\\\wbfm_3d_Charlie95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\charles.fieseler\\\\Anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_wbfm_3dOct21\\\\Documentation_data-wbfm_3d_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.02, 1000], [0.005, 5000], [0.001, 20000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\charles.fieseler\\\\Documents\\\\Current_work\\\\DLC_for_WBFM\\\\DLC_Projects\\\\wbfm_3d-Charlie-2020-10-21',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'rotate_max_deg_abs': 180,\n",
      " 'rotation': 180,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\charles.fieseler\\\\Documents\\\\Current_work\\\\DLC_for_WBFM\\\\DLC_Projects\\\\wbfm_3d-Charlie-2020-10-21\\\\dlc-models\\\\iteration-0\\\\wbfm_3dOct21-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21/evaluation-results/  already exists!\n",
      "C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\evaluation-results\\iteration-0\\wbfm_3dOct21-trainset95shuffle1  already exists!\n",
      "Running  DLC_resnet50_wbfm_3dOct21shuffle1_20000  with # of trainingiterations: 20000\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\dlc-models\\iteration-0\\wbfm_3dOct21-trainset95shuffle1\\train\\snapshot-20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:02, 11.81it/s]\n",
      "  0%|                                                                                           | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-20000\n",
      "Results for 20000  training iterations: 95 1 train error: 1.95 pixels. Test error: 1.25  pixels.\n",
      "With pcutoff of 0.6  train error: 1.95 pixels. Test error: 1.25 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:08<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get video in default folder\n",
    "cfg = deeplabcut.auxiliaryfunctions.read_config(path_config_file)\n",
    "video_fname = [i for i in cfg['video_sets'].keys()] # Assume one video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\charles.fieseler\\\\Documents\\\\Current_work\\\\DLC_for_WBFM\\\\DLC_Projects\\\\wbfm_3d-Charlie-2020-10-21\\\\videos\\\\mcherry_frames1000_slice17_22.avi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2]],\n",
      " 'all_joints_names': ['neuron0', 'neuron1', 'neuron2'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_wbfm_3dOct21\\\\wbfm_3d_Charlie95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\charles.fieseler\\\\Anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_wbfm_3dOct21\\\\Documentation_data-wbfm_3d_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.02, 1000], [0.005, 5000], [0.001, 20000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 3,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\charles.fieseler\\\\Documents\\\\Current_work\\\\DLC_for_WBFM\\\\DLC_Projects\\\\wbfm_3d-Charlie-2020-10-21',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'rotate_max_deg_abs': 180,\n",
      " 'rotation': 180,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\charles.fieseler\\\\Documents\\\\Current_work\\\\DLC_for_WBFM\\\\DLC_Projects\\\\wbfm_3d-Charlie-2020-10-21\\\\dlc-models\\\\iteration-0\\\\wbfm_3dOct21-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-20000 for model C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\dlc-models\\iteration-0\\wbfm_3dOct21-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\dlc-models\\iteration-0\\wbfm_3dOct21-trainset95shuffle1\\train\\snapshot-20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                         | 0/1001 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\videos\\mcherry_frames1000_slice17_22.avi\n",
      "Loading  C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\videos\\mcherry_frames1000_slice17_22.avi\n",
      "Duration of video [s]:  100.1 , recorded with  10.0 fps!\n",
      "Overall # of frames:  1001  found with (before cropping) frame dimensions:  900 700\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:41, 19.95it/s]                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1010it [00:41, 24.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\videos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_wbfm_3dOct21shuffle1_20000'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "deeplabcut.analyze_videos(path_config_file,video_fname, videotype='.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. \n",
    "\n",
    "THIS HAS MANY FUN OPTIONS! \n",
    "\n",
    "``deeplabcut.create_labeled_video(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, filtered=False, save_frames=False, Frames2plot=None, delete=False, displayedbodyparts='all', codec='mp4v', outputframerate=None, destfolder=None, draw_skeleton=False, trailpoints=0, displaycropped=False)``\n",
    "\n",
    "So please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1001 [00:00<?, ?it/s]C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\utils\\make_labeled_video.py:114: FutureWarning: circle is deprecated in favor of disk.circle will be removed in version 0.19\n",
      "  rr, cc = circle(yc,xc,dotsize,shape=(ny,nx))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\videos ['C:\\\\Users\\\\charles.fieseler\\\\Documents\\\\Current_work\\\\DLC_for_WBFM\\\\DLC_Projects\\\\wbfm_3d-Charlie-2020-10-21\\\\videos\\\\mcherry_frames1000_slice17_22.avi']\n",
      "Loading  C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\videos\\mcherry_frames1000_slice17_22.avi and data.\n",
      "1001\n",
      "Duration of video [s]:  100.1 , recorded with  10.0 fps!\n",
      "Overall # of frames:  1001 with cropped frame dimensions:  900 700\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1001/1001 [00:05<00:00, 170.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# video_fname = os.path.join(project_folder, 'videos/27082020_trial2_HEAD_500frames_mcherry_slice8.avi')\n",
    "\n",
    "deeplabcut.create_labeled_video(path_config_file,video_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [optional step]\n",
    "\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. This step has many options, so please look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method  jump  found  983  putative outlier frames.\n",
      "Do you want to proceed with extracting  10  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "yes/noyes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [00:00, 201.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames from video mcherry_frames1000_slice17_22  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  100.1 , recorded @  10.0 fps!\n",
      "Overall # of frames:  1001 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 100.1  seconds.\n",
      "Extracting and downsampling... 983  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "983it [00:05, 189.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [197, 145, 389, 767, 557, 708, 104, 188, 390, 237]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:463: UserWarning: C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\labeled-data\\mcherry_frames1000_slice17_22\\img0197.png is a low contrast image\n",
      "  io.imsave(imagename1,image)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:463: UserWarning: C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\labeled-data\\mcherry_frames1000_slice17_22\\img0389.png is a low contrast image\n",
      "  io.imsave(imagename1,image)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:463: UserWarning: C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\labeled-data\\mcherry_frames1000_slice17_22\\img0767.png is a low contrast image\n",
      "  io.imsave(imagename1,image)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:463: UserWarning: C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\labeled-data\\mcherry_frames1000_slice17_22\\img0557.png is a low contrast image\n",
      "  io.imsave(imagename1,image)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:463: UserWarning: C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\labeled-data\\mcherry_frames1000_slice17_22\\img0708.png is a low contrast image\n",
      "  io.imsave(imagename1,image)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:463: UserWarning: C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\labeled-data\\mcherry_frames1000_slice17_22\\img0104.png is a low contrast image\n",
      "  io.imsave(imagename1,image)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:463: UserWarning: C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\labeled-data\\mcherry_frames1000_slice17_22\\img0188.png is a low contrast image\n",
      "  io.imsave(imagename1,image)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:463: UserWarning: C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\labeled-data\\mcherry_frames1000_slice17_22\\img0390.png is a low contrast image\n",
      "  io.imsave(imagename1,image)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\refine_training_dataset\\outlier_frames.py:463: UserWarning: C:\\Users\\charles.fieseler\\Documents\\Current_work\\DLC_for_WBFM\\DLC_Projects\\wbfm_3d-Charlie-2020-10-21\\labeled-data\\mcherry_frames1000_slice17_22\\img0237.png is a low contrast image\n",
      "  io.imsave(imagename1,image)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\mcherry_frames1000_slice17_22.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file,video_fname) #pass a specific video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "%gui wx\n",
    "deeplabcut.refine_training_dataset.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Afterwards, if you want to look at the adjusted frames, you can load them in the main GUI by running: ``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "(you can add a new \"cell\" below to add this code!)\n",
    "\n",
    "#### Once all folders are relabeled, check the labels again! If you are not happy, adjust them in the main GUI:\n",
    "\n",
    "``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "Check Labels:\n",
    "\n",
    "``deeplabcut.check_labels(path_config_file)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [],
   "source": [
    "#NOW, merge this with your original data:\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refinement of labels and appending them to the original dataset, this creates a new iteration of training dataset. This is automatically set in the config.yaml file, so let's get training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:DLC-GPU] *",
   "language": "python",
   "name": "conda-env-DLC-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
