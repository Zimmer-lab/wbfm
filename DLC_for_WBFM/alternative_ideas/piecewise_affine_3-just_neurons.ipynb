{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5830b566-e6b5-40ab-ae07-c2fc4b1c75cc",
   "metadata": {},
   "source": [
    "# Experiments with GP pushing and then simulated annealing for finalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "852a500a-c726-458b-b2a1-e07ebaac1bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from DLC_for_WBFM.utils.projects.finished_project_data import finished_project_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import napari, zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e99ec9f1-3239-4260-abdf-e40d99492b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = r\"C:\\dlc_stacks\\Charlie-worm3-new-seg\\project_config.yaml\"\n",
    "dat = finished_project_data.load_final_project_data_from_config(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f8477c0-ba7a-4a3b-9458-e4dbaa113c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "fname = r\"C:\\dlc_stacks\\Charlie-worm3-new-seg\\2-training_data\\raw\\match_dat.pickle\"\n",
    "with open(fname, 'rb') as f:\n",
    "    matches = pickle.load(f)\n",
    "    \n",
    "fname = r\"C:\\dlc_stacks\\Charlie-worm3-new-seg\\2-training_data\\raw\\frame_dat.pickle\"\n",
    "with open(fname, 'rb') as f:\n",
    "    frames = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a64f2-2a49-4e4d-a10f-fea62a1c6e17",
   "metadata": {},
   "source": [
    "# Visualize the pushed neurons on the next frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c271727-fc5e-470b-8762-0fe8765f7bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FramePair with 134 matches \n",
      "\n",
      "=======================================\n",
      "ReferenceFrame:\n",
      "Frame index: 0 \n",
      "Number of neurons: 148 \n",
      "Number of keypoints: 148 \n",
      " =======================================\n",
      "ReferenceFrame:\n",
      "Frame index: 1 \n",
      "Number of neurons: 151 \n",
      "Number of keypoints: 151 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pair = (0, 1)\n",
    "print(matches[pair])\n",
    "print(frames[pair[0]], frames[pair[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa9cf427-9789-40ac-a225-9fea34f97756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get locations of target neurons\n",
    "target_zxy = frames[pair[1]].neuron_locs\n",
    "target_zxy = target_zxy[:, [0,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5db58fcd-c212-4aae-9ce5-a0742c3fcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gp pushed locations\n",
    "\n",
    "gp_zxy = matches[pair].gp_pushed_locations\n",
    "# Replace z coordinate, which is somehow crazy\n",
    "gp_zxy[:, 0] = frames[pair[0]].neuron_locs[:, 0]\n",
    "gp_zxy = gp_zxy[:, [0,2,1]]\n",
    "\n",
    "affine_zxy = matches[pair].affine_pushed_locations\n",
    "# Replace z coordinate, which is somehow crazy\n",
    "# affine_zxy[:, 0] = frames[pair[0]].neuron_locs[:, 0]\n",
    "affine_zxy = affine_zxy[:, [0,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faf756d6-bddb-438c-b1b7-98458e3a6cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by \"has match\"\n",
    "f0_to_f1_matches = {n0: n1 for n0, n1, _ in matches[pair].final_matches}\n",
    "\n",
    "# F1 matches\n",
    "has_match_ind = set(f0_to_f1_matches.values())\n",
    "target_xyz_matched = [row for i, row in enumerate(target_zxy) if i in has_match_ind]\n",
    "target_xyz_unmatched = [row for i, row in enumerate(target_zxy) if i not in has_match_ind]\n",
    "\n",
    "# F0 matches\n",
    "has_match_ind = set(f0_to_f1_matches.keys())\n",
    "\n",
    "gp_xyz_matched = [row for i, row in enumerate(gp_zxy) if i in has_match_ind]\n",
    "gp_xyz_unmatched = [row for i, row in enumerate(gp_zxy) if i not in has_match_ind]\n",
    "\n",
    "affine_xyz_matched = [row for i, row in enumerate(affine_zxy) if i in has_match_ind]\n",
    "affine_xyz_unmatched = [row for i, row in enumerate(affine_zxy) if i not in has_match_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f956a44b-cfeb-4cf5-9658-95c5065e7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot using napari\n",
    "# v = napari.view_image(dat.red_data[pair[1]], ndisplay=3)\n",
    "# # v.add_points(gp_xyz_matched, size=3, face_color='green', n_dimensional=True)\n",
    "# v.add_points(gp_xyz_unmatched, size=3, face_color='red', n_dimensional=True)\n",
    "# # v.add_points(affine_xyz_matched, size=3, face_color='green', symbol='x', n_dimensional=True)\n",
    "# v.add_points(affine_xyz_unmatched, size=3, face_color='red', symbol='x', n_dimensional=True)\n",
    "# v.add_points(target_xyz_matched, size=5, symbol='ring', face_color='blue', n_dimensional=True)\n",
    "# v.add_points(target_xyz_unmatched, size=5, symbol='ring', face_color='red', n_dimensional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba692ea2-9a06-4000-b6b0-46e3798cdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get gradient images (not in z)\n",
    "# vol = dat.red_data[pair[1], ...]\n",
    "# vol_filtered = gaussian(vol, sigma=1)\n",
    "# thresh = 1.5*np.mean(vol_filtered)\n",
    "# mask = vol_filtered > thresh\n",
    "# vol_gradient_x = sobel_h(vol_filtered, mask)\n",
    "# vol_gradient_y = sobel_v(vol_filtered, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea031a-a12a-4a11-9d42-6c8f9522c6d7",
   "metadata": {},
   "source": [
    "# Actually do it (no annealing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32a8e0c7-c9e5-4ef1-aaa7-183b9d945d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skimage.filters import gaussian, sobel_h, sobel_v\n",
    "from scipy.spatial import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19146984-7d0a-4aee-b6eb-9e5dbde90279",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "baf294f3-9fee-4f4c-8f98-e48a63ac3b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get initial affine locations\n",
    "affine_zxy = matches[pair].affine_pushed_locations\n",
    "affine_zxy = affine_zxy[:, [0,2,1]]\n",
    "\n",
    "# Get image\n",
    "vol = dat.red_data[pair[1], ...]\n",
    "# vol_filtered = gaussian(vol, sigma=1)\n",
    "\n",
    "# Get locations of target neurons\n",
    "target_zxy = frames[pair[1]].neuron_locs\n",
    "target_zxy = target_zxy[:, [0,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b1dfa1b-f7cc-4a5e-95ef-3ed7cd2e7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only check the ones with no match\n",
    "f0_to_f1_matches = {n0: n1 for n0, n1, _ in matches[pair].final_matches}\n",
    "has_match_ind = list(f0_to_f1_matches.keys())\n",
    "no_match_ind = list(range(frames[pair[0]].num_neurons()))\n",
    "[no_match_ind.remove(i) for i in has_match_ind]\n",
    "\n",
    "# Set up kdtree to check nearest neighbor\n",
    "tree = KDTree(target_zxy)\n",
    "\n",
    "# Parameters\n",
    "brightness_thresh = 25\n",
    "distance_thresh = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aec94ec7-4bd5-40d0-a7c3-906313864388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0 278.634677184079\n",
      "False 22 6.514810434866421\n",
      "True 40 8.798306660844792\n",
      "False 31 3.65074508888712\n",
      "False 34 4.273267236144742\n",
      "True 36 9.445009640142503\n",
      "True 27 12.186874485455414\n",
      "True 35 7.80057086110525\n",
      "Added 4 neurons\n"
     ]
    }
   ],
   "source": [
    "new_f1_zxy = []\n",
    "new_matches = []\n",
    "next_f1_ind = frames[pair[1]].num_neurons() + 1\n",
    "\n",
    "for ind_f0 in no_match_ind:\n",
    "    pushed_zxy = affine_zxy[ind_f0, :]\n",
    "    z, x, y = int(pushed_zxy[0]), int(pushed_zxy[1]), int(pushed_zxy[2])\n",
    "    brightness = vol[z, x, y]\n",
    "    \n",
    "    nn_dist, _ = tree.query(pushed_zxy, k=1)\n",
    "    \n",
    "    to_keep = (brightness > brightness_thresh) and (nn_dist > distance_thresh)\n",
    "    print(to_keep, brightness, nn_dist)\n",
    "    if to_keep:\n",
    "        new_matches.append([ind_f0, next_f1_ind, 1.0])\n",
    "        next_f1_ind += 1\n",
    "        new_f1_zxy.append(pushed_zxy)\n",
    "\n",
    "print(f\"Added {len(new_matches)} neurons\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0da1640-d584-4017-8970-4845eb50a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot using napari\n",
    "# v = napari.view_image(dat.red_data[pair[1]], ndisplay=3)\n",
    "# v.add_points(new_f1_zxy, size=3, face_color='green', symbol='x', n_dimensional=True)\n",
    "# v.add_points(affine_xyz_unmatched, size=3, face_color='red', symbol='x', n_dimensional=True)\n",
    "# v.add_points(target_xyz_matched, size=5, symbol='ring', face_color='blue', n_dimensional=True)\n",
    "# v.add_points(target_xyz_unmatched, size=5, symbol='ring', face_color='red', n_dimensional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a6a3ac-f770-4dea-ab0a-837bf377d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0, f1 = frames[pair[0]], frames[pair[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a99f243-e643-44ad-9919-63419db880f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f0.keypoint_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7457a5f3-b1de-4993-8e91-fcf3c2140f5e",
   "metadata": {},
   "source": [
    "# Use piecewise affine with only matched neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cc64b3e-d382-4565-8b74-28a456e1e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import PiecewiseAffineTransform, warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7a9e2fb-06df-4048-9af6-abc80998ce0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FramePair with 134 matches \n",
      "\n",
      "=======================================\n",
      "ReferenceFrame:\n",
      "Frame index: 0 \n",
      "Number of neurons: 148 \n",
      "Number of keypoints: 148 \n",
      " =======================================\n",
      "ReferenceFrame:\n",
      "Frame index: 1 \n",
      "Number of neurons: 151 \n",
      "Number of keypoints: 151 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pair = (0, 1)\n",
    "print(matches[pair])\n",
    "print(frames[pair[0]], frames[pair[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69d19f68-d279-4d8c-b9ac-f41030df5120",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = matches[pair]\n",
    "f0, f1 = frames[pair[0]], frames[pair[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b2ffe7-5bff-477d-84f2-2e5d9a5deda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_to_f1 = m.get_f0_to_f1_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60dda4a2-473f-4253-8d62-4d9802a95e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_matched = np.array([f0.keypoint_locs[k,[2,1]] for k in f0_to_f1.keys()])\n",
    "src_all_xy = np.array(f0.keypoint_locs[:,[2,1]])\n",
    "src_z = np.array(f0.keypoint_locs[:,[0]])\n",
    "\n",
    "dst_matched = np.array([f1.keypoint_locs[v,[2,1]] for v in f0_to_f1.values()])\n",
    "dst_all_xy = np.array(f0.keypoint_locs[:,[2,1]])\n",
    "dst_z = np.array(f0.keypoint_locs[:,[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27bc9700-f6a3-40f7-9835-9a7a7a8d0b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tform = PiecewiseAffineTransform()\n",
    "tform.estimate(src_matched, dst_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "092c3266-449a-4c48-ba86-8ed77f1a1ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = tform.inverse(dst_all_xy)\n",
    "# src_transformed = tform.inverse(src)\n",
    "\n",
    "transformed = np.where(transformed==-1, np.nan, transformed)\n",
    "\n",
    "transformed = np.hstack([dst_z, transformed]) #[:, [0,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "793ca1e5-1b3e-4b2a-a22c-46f012e8e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get locations of target neurons\n",
    "target_zxy = frames[pair[1]].neuron_locs\n",
    "target_zxy = target_zxy[:, [0,2,1]]\n",
    "\n",
    "affine_zxy = matches[pair].affine_pushed_locations\n",
    "affine_zxy = affine_zxy[:, [0,2,1]]\n",
    "\n",
    "# Split by \"has match\"\n",
    "f0_to_f1_matches = {n0: n1 for n0, n1, _ in matches[pair].final_matches}\n",
    "\n",
    "# F1 matches\n",
    "has_match_ind = set(f0_to_f1_matches.values())\n",
    "target_xyz_matched = [row for i, row in enumerate(target_zxy) if i in has_match_ind]\n",
    "target_xyz_unmatched = [row for i, row in enumerate(target_zxy) if i not in has_match_ind]\n",
    "\n",
    "# F0 matches\n",
    "has_match_ind = set(f0_to_f1_matches.keys())\n",
    "\n",
    "affine_xyz_matched = [row for i, row in enumerate(affine_zxy) if i in has_match_ind]\n",
    "affine_xyz_unmatched = [row for i, row in enumerate(affine_zxy) if i not in has_match_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8bd27ad-495d-4658-b2d5-605fec31a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot using napari\n",
    "# v = napari.view_image(dat.red_data[pair[0]], ndisplay=3, name='f0_red')\n",
    "# v.add_image(dat.red_data[pair[1]], name='f1_red')\n",
    "# v.add_points(transformed, size=3, face_color='red', n_dimensional=True, name='piecewise_affine_transformed')\n",
    "# v.add_points(affine_xyz_matched, size=3, face_color='green', symbol='x', n_dimensional=True, name='f0_affine_matched')\n",
    "# # v.add_points(affine_xyz_unmatched, size=3, face_color='red', symbol='x', n_dimensional=True)\n",
    "# v.add_points(target_xyz_matched, size=5, symbol='ring', face_color='blue', n_dimensional=True, name='f1_matched')\n",
    "# v.add_points(target_xyz_unmatched, size=5, symbol='ring', face_color='red', n_dimensional=True, name='f1_unmatched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d9537e5-8995-4fab-b857-c46025130065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tform.estimate(dst, src)\n",
    "# src_transformed = tform.inverse(src)\n",
    "# # src_transformed = tform.inverse(f0.keypoint_locs[:,[2,1]])\n",
    "\n",
    "# src_transformed[:3], dst[:3], src[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06ddc9-5a51-4c91-b1ce-c06c0febd697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ec6920-a662-4625-a23f-cbac26fa8fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be9b897-b205-4b15-a223-db4949f2034d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3ede5b2-c115-45c9-bf4e-41167351121a",
   "metadata": {},
   "source": [
    "# Piecewise affine, but add additional ORB features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6b6db17-1c58-422a-9cca-ab4c6b154d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import PiecewiseAffineTransform, warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6410cce-0ec5-4348-81fc-e0d3db0c5d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FramePair with 134 matches \n",
      "\n",
      "=======================================\n",
      "ReferenceFrame:\n",
      "Frame index: 0 \n",
      "Number of neurons: 148 \n",
      "Number of keypoints: 148 \n",
      " =======================================\n",
      "ReferenceFrame:\n",
      "Frame index: 1 \n",
      "Number of neurons: 151 \n",
      "Number of keypoints: 151 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pair = (0, 1)\n",
    "pair_obj = matches[pair]\n",
    "print(pair_obj)\n",
    "f0, f1 = frames[pair[0]], frames[pair[1]]\n",
    "print(f0, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d29afc0-7ed3-4dc3-9d70-41ae09aa60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Frame classes, if old style\n",
    "pair_obj.frame0, pair_obj.frame1 = f0, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a02ad2a9-f984-4bfd-87b8-3d0d478cb4b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'err' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-ea5d7e39dd60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'err' is not defined"
     ]
    }
   ],
   "source": [
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223ea1fc-f2c5-4aec-82aa-3c817fd1c734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3fccf45b-7782-4c47-ab4f-cf380575f21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReferenceFrame with 148 neurons "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195633be-0d80-448e-af52-f0720470b1fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_dat = dat.red_data[pair[0],...]\n",
    "\n",
    "# f0.detect_non_neuron_keypoints(video_dat, append_to_existing_keypoints=True)\n",
    "f0.encode_all_keypoints(video_dat, z_depth=0)\n",
    "# f0.build_nontrivial_keypoint_to_neuron_mapping(neuron_feature_radius=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607132bd-7696-4183-b2aa-77a0cc2ffe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DLC_for_WBFM.utils.feature_detection.utils_features import convert_to_grayscale\n",
    "import cv2\n",
    "\n",
    "loc = f0.neuron_locs[0]\n",
    "\n",
    "z, x, y = loc\n",
    "kp_2d = cv2.KeyPoint(x, y, 31.0)\n",
    "base_2d_encoder = cv2.xfeatures2d.VGG_create()\n",
    "im_3d_gray = [convert_to_grayscale(xy).astype('uint8') for xy in video_dat]\n",
    "im_2d = im_3d_gray[int(5)]\n",
    "_, this_ds = base_2d_encoder.compute(im_2d, [kp_2d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae1ee6-ad4d-43e4-b3aa-8874d86cb3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1806c6-a3c1-4ec2-ae0e-43b76d332fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0.all_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7c295-9616-4dfa-8573-b94fbdd8d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = matches[pair]\n",
    "f0, f1 = frames[pair[0]], frames[pair[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1669491-744f-43ec-93cd-32c82adf9bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_to_f1 = m.get_f0_to_f1_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae7f25f-03c3-49a4-a57b-01cb9aee4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_matched = np.array([f0.neuron_locs[k,[2,1]] for k in f0_to_f1.keys()])\n",
    "src_all_xy = np.array(f0.neuron_locs[:,[2,1]])\n",
    "src_z = np.array(f0.neuron_locs[:,[0]])\n",
    "\n",
    "dst_matched = np.array([f1.neuron_locs[v,[2,1]] for v in f0_to_f1.values()])\n",
    "dst_all_xy = np.array(f0.neuron_locs[:,[2,1]])\n",
    "dst_z = np.array(f0.neuron_locs[:,[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51b3b7d-69b5-4f06-ab3b-77c5d2e9d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tform = PiecewiseAffineTransform()\n",
    "tform.estimate(src_matched, dst_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af59b0-0b5d-42dd-a9d0-c1e4f77cc244",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = tform.inverse(dst_all_xy)\n",
    "# src_transformed = tform.inverse(src)\n",
    "\n",
    "transformed = np.where(transformed==-1, np.nan, transformed)\n",
    "\n",
    "transformed = np.hstack([dst_z, transformed]) #[:, [0,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5edb1ab-25a0-4b69-a7e8-388a4b993afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get locations of target neurons\n",
    "target_zxy = frames[pair[1]].neuron_locs\n",
    "target_zxy = target_zxy[:, [0,2,1]]\n",
    "\n",
    "affine_zxy = matches[pair].affine_pushed_locations\n",
    "affine_zxy = affine_zxy[:, [0,2,1]]\n",
    "\n",
    "# Split by \"has match\"\n",
    "f0_to_f1_matches = {n0: n1 for n0, n1, _ in matches[pair].final_matches}\n",
    "\n",
    "# F1 matches\n",
    "has_match_ind = set(f0_to_f1_matches.values())\n",
    "target_xyz_matched = [row for i, row in enumerate(target_zxy) if i in has_match_ind]\n",
    "target_xyz_unmatched = [row for i, row in enumerate(target_zxy) if i not in has_match_ind]\n",
    "\n",
    "# F0 matches\n",
    "has_match_ind = set(f0_to_f1_matches.keys())\n",
    "\n",
    "affine_xyz_matched = [row for i, row in enumerate(affine_zxy) if i in has_match_ind]\n",
    "affine_xyz_unmatched = [row for i, row in enumerate(affine_zxy) if i not in has_match_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d989f975-16d3-422d-91ed-e95fb58cebe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot using napari\n",
    "v = napari.view_image(dat.red_data[pair[0]], ndisplay=3, name='f0_red')\n",
    "v.add_image(dat.red_data[pair[1]], name='f1_red')\n",
    "v.add_points(transformed, size=3, face_color='red', n_dimensional=True, name='piecewise_affine_transformed')\n",
    "v.add_points(affine_xyz_matched, size=3, face_color='green', symbol='x', n_dimensional=True, name='f0_affine_matched')\n",
    "# v.add_points(affine_xyz_unmatched, size=3, face_color='red', symbol='x', n_dimensional=True)\n",
    "v.add_points(target_xyz_matched, size=5, symbol='ring', face_color='blue', n_dimensional=True, name='f1_matched')\n",
    "v.add_points(target_xyz_unmatched, size=5, symbol='ring', face_color='red', n_dimensional=True, name='f1_unmatched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c673ce-4959-4ce8-aa1d-c9d02f766e46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4171802-2a2f-4638-b7f5-bf16f06d82d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e18db-9174-40dd-a403-cda79c052b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcae7b3-512e-4d6f-8d56-6ffb8abb23a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ff75a15-6f36-4e6e-abb2-89b12278d753",
   "metadata": {},
   "source": [
    "# Basic encoding tests: do matches change based on VGG z depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52ac1960-b347-439d-b5ed-ebba3dcee82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DLC_for_WBFM.utils.feature_detection.class_frame_pair import calc_FramePair_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "030f9409-bfa2-4d4d-89fb-42360031f1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FramePair with 134/148 matches \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pair = (0, 1)\n",
    "pair_obj = matches[pair]\n",
    "print(pair_obj)\n",
    "f0, f1 = frames[pair[0]], frames[pair[1]]\n",
    "# print(f0, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d767c0f-c7ee-4134-82e1-484a3c8c796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix old style\n",
    "pair_obj.frame0, pair_obj.frame1 = f0, f1\n",
    "\n",
    "pair_obj.add_affine_to_candidates=True\n",
    "pair_obj.add_gp_to_candidates=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "efe69535-ed6b-4a39-a46d-1d8863438b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing keypoints...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing keypoints...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\segmentation\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:409: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__sigma_0 is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\segmentation\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:409: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__sigma_0 is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\segmentation\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:409: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-08. Decreasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\segmentation\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:409: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__sigma_0 is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\segmentation\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:409: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-08. Decreasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FramePair with 134/148 matches \n",
      "\n"
     ]
    }
   ],
   "source": [
    "f0_video_dat = dat.red_data[pair[0],...]\n",
    "f1_video_dat = dat.red_data[pair[1],...]\n",
    "\n",
    "# Redo encoding with no z depth\n",
    "f0.rebuild_keypoints()\n",
    "f0.encode_all_keypoints(f0_video_dat, z_depth=5)\n",
    "f1.rebuild_keypoints()\n",
    "f1.encode_all_keypoints(f1_video_dat, z_depth=5)\n",
    "# Note: do not need to change keypoint-neuron matching\n",
    "\n",
    "# Redo matching (new pair object)\n",
    "new_pair5 = calc_FramePair_like(pair_obj, f0, f1)\n",
    "\n",
    "# Compare\n",
    "print(new_pair5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "926e14a7-1069-4d49-850b-9f7268b58c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing keypoints...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing keypoints...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/151 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FramePair with 134/148 matches \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\segmentation\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:409: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__sigma_0 is close to the specified lower bound 0.001. Decreasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\charles.fieseler\\Anaconda3\\envs\\segmentation\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:409: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified lower bound 1e-08. Decreasing the bound and calling fit again may find a better value.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "f0_video_dat = dat.red_data[pair[0],...]\n",
    "f1_video_dat = dat.red_data[pair[1],...]\n",
    "\n",
    "# Redo encoding with no z depth\n",
    "f0.rebuild_keypoints()\n",
    "f0.encode_all_keypoints(f0_video_dat, z_depth=0)\n",
    "f1.rebuild_keypoints()\n",
    "f1.encode_all_keypoints(f1_video_dat, z_depth=0)\n",
    "\n",
    "# Redo matching (new pair object)\n",
    "new_pair0 = calc_FramePair_like(pair_obj, f0, f1)\n",
    "\n",
    "# Compare\n",
    "print(new_pair0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "17930c2d-81d6-43a0-b4d2-cb66570c5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f0_map_0 = new_pair0.get_f0_to_f1_dict()\n",
    "f0_map_5 = new_pair5.get_f0_to_f1_dict()\n",
    "\n",
    "f0_conf_0 = new_pair0.get_pair_to_conf_dict()\n",
    "f0_conf_5 = new_pair5.get_pair_to_conf_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "21dc326d-4313-4e71-9a05-2fb09491aec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 68 132\n",
      "conf:  0.5802337759857685 0.19394127314555554\n",
      "8 : 133 None\n",
      "conf:  0.20329414440551336 None\n",
      "53 : 28 3\n",
      "conf:  0.034576344527244174 0.8329925214772761\n",
      "65 : None 28\n",
      "conf:  None 0.059030207580770044\n",
      "68 : 110 87\n",
      "conf:  0.5058319859765046 0.6010213441295417\n",
      "89 : 72 141\n",
      "conf:  0.5223284961253418 0.435534410306495\n",
      "92 : 123 147\n",
      "conf:  0.8802500567772639 0.882614979999581\n",
      "96 : 26 None\n",
      "conf:  0.5436642479928631 None\n",
      "108 : 136 47\n",
      "conf:  0.03495570191596903 0.04567313772047888\n",
      "112 : 125 99\n",
      "conf:  0.037409675256080334 0.04925594002648937\n",
      "119 : None 72\n",
      "conf:  None 0.27807912347449676\n",
      "125 : 64 26\n",
      "conf:  0.02562587099526899 0.18304152447565425\n",
      "133 : None 110\n",
      "conf:  None 0.32043749575602753\n",
      "134 : 76 64\n",
      "conf:  0.4720994028390446 0.14700837814657383\n",
      "136 : None 133\n",
      "conf:  None 0.1142504102580618\n",
      "138 : 106 131\n",
      "conf:  0.4602121839039434 0.14859702931744703\n",
      "140 : 31 74\n",
      "conf:  0.4584115341724631 0.1644526550717106\n",
      "142 : 87 None\n",
      "conf:  0.5025743023815904 None\n",
      "145 : 3 None\n",
      "conf:  0.5017519312086033 None\n",
      "Number of mismatches 19\n"
     ]
    }
   ],
   "source": [
    "num_mismatches = 0\n",
    "all_keys = set(f0_map_0.keys())\n",
    "all_keys.update(tuple(f0_map_5.keys()))\n",
    "for i in all_keys:\n",
    "    m0, m5 = f0_map_0.get(i,None), f0_map_5.get(i,None)\n",
    "    if m0 != m5:\n",
    "        print(i, ':', m0, m5)\n",
    "        print('conf: ', f0_conf_0.get((i, m0), None), f0_conf_5.get((i, m5), None))\n",
    "        num_mismatches += 1\n",
    "print(f\"Number of mismatches {num_mismatches}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c80bcf4-8026-4bdf-83f1-a0720894492c",
   "metadata": {},
   "source": [
    "# Scratch: sanity checks for the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad216e-7a66-4088-bb24-fb0833d25c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = r\"C:\\dlc_stacks\\Test_project\\2-training_data\\all_tracklets.h5\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_hdf(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1562aa-4f94-4409-b096-b801b6485ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff625f0f-b2f4-4d9e-a263-f392ac1d7706",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diff()[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef729d7d-533c-4a13-bfcb-fb94610436b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neurons = list(df.columns.levels[0])\n",
    "for n in all_neurons:\n",
    "    zd = df.diff()[1:][n]['z']\n",
    "    if all(abs(zd) > 2):\n",
    "        print(n, list(zd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec681db-8dc6-4e21-9562-46468edc68e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(np.arange(10), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64542362-f76c-4702-9a85-e23068395918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba8ba08-5c4d-43e7-bcea-cf3ca8730688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:segmentation]",
   "language": "python",
   "name": "conda-env-segmentation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
