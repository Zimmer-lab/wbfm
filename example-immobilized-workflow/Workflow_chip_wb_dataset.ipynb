{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DLC for WBFM analysis: chip setup\n",
    "\n",
    "This workflow requires three preparation steps:\n",
    "\n",
    "- Preprocessing from .stk to a large ome.tiff file, currently using FIJI\n",
    "- Conversion of a slice to .avi, currently using Python\n",
    "- Manual labeling with the DLC gui, on a local machine\n",
    "    - Then the created project should be copied to the cluster where this training is run\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Load locally-labeled project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLClight=True\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "%env DLClight=True\n",
    "import deeplabcut\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Copied from the local machine\n",
    "# project_folder = '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12'\n",
    "project_folder = '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8_FULL-Charlie-2020-10-15'\n",
    "path_config_file = os.path.join(project_folder, 'config.yaml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the path files to be Unix, not Windows\n",
    "\n",
    "Notes on how to do this programmatically:\n",
    "https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/maDLC_AdvUserGuide.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_fname = os.path.join(project_folder, 'videos/27082020_trial2_HEAD_500frames_mcherry_slice8.avi')\n",
    "# video_fname = '/users/charles.fieseler/shared_projects/wbfm/dat/immobilized_wbfm_hardware/27082020_trial2_dual1_HEAD_500frames_mcherry_slice8.avi'\n",
    "edits = {'project_path': project_folder,\n",
    "        'video_sets': {video_fname : {'crop':[0, 332, 0, 132]}}}\n",
    "\n",
    "deeplabcut.auxiliaryfunctions.edit_config(path_config_file, edits);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "\n",
    "This function generates the training data information for network training based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles if they want to benchmark the performance (typcailly, 1 is what you will set, so you pass nothing!). \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**. For most all use cases we have seen, the defaults are perfectly fine.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8_FULL-Charlie-2020-10-15/training-datasets/iteration-0/UnaugmentedDataSet_Chip_with_WBFM_hardware_z8_FULLOct15  already exists!\n",
      "It appears that the images were labeled on a Windows system, but you are currently trying to create a training set on a Unix system. \n",
      " In this case the paths should be converted. Do you want to proceed with the conversion?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "yes/no yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation data converted to unix format...\n",
      "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz....\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95, 1, (array([3, 8, 0, 2, 6, 5, 4, 7]), array([1])))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "#remember, there are several networks you can pick, the default is resnet-50!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training:\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8]],\n",
      " 'all_joints_names': ['AVA',\n",
      "                      'RIB',\n",
      "                      'SMDV',\n",
      "                      'SMDD',\n",
      "                      'RIV',\n",
      "                      'ASK1',\n",
      "                      'ASK2',\n",
      "                      'ASK3',\n",
      "                      'ASK4'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Chip_with_WBFM_hardware_z8_FULLOct15/Chip_with_WBFM_hardware_z8_FULL_Charlie95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/users/charles.fieseler/.conda/envs/DLC-CPU-dev/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Chip_with_WBFM_hardware_z8_FULLOct15/Documentation_data-Chip_with_WBFM_hardware_z8_FULL_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 9,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8_FULL-Charlie-2020-10-15',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8_FULL-Charlie-2020-10-15/dlc-models/iteration-0/Chip_with_WBFM_hardware_z8_FULLOct15-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\n",
      "Starting with standard pose-dataset loader.\n",
      "Initializing ResNet\n",
      "WARNING:tensorflow:From /users/charles.fieseler/.conda/envs/DLC-CPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /users/charles.fieseler/.conda/envs/DLC-CPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "WARNING:tensorflow:From /users/charles.fieseler/.conda/envs/DLC-CPU-dev/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /users/charles.fieseler/.conda/envs/DLC-CPU-dev/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt\n",
      "Display_iters overwritten as 250\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8_FULL-Charlie-2020-10-15/dlc-models/iteration-0/Chip_with_WBFM_hardware_z8_FULLOct15-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8]], 'all_joints_names': ['AVA', 'RIB', 'SMDV', 'SMDD', 'RIV', 'ASK1', 'ASK2', 'ASK3', 'ASK4'], 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Chip_with_WBFM_hardware_z8_FULLOct15/Chip_with_WBFM_hardware_z8_FULL_Charlie95shuffle1.mat', 'display_iters': 1000, 'init_weights': '/users/charles.fieseler/.conda/envs/DLC-CPU-dev/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Chip_with_WBFM_hardware_z8_FULLOct15/Documentation_data-Chip_with_WBFM_hardware_z8_FULL_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 9, 'pos_dist_thresh': 17, 'project_path': '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8_FULL-Charlie-2020-10-15', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'output_stride': 16, 'deconvolutionstride': 2}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 250 loss: 0.0601 lr: 0.005\n",
      "iteration: 500 loss: 0.0166 lr: 0.005\n",
      "iteration: 750 loss: 0.0120 lr: 0.005\n",
      "iteration: 1000 loss: 0.0102 lr: 0.005\n",
      "iteration: 1250 loss: 0.0097 lr: 0.005\n",
      "iteration: 1500 loss: 0.0094 lr: 0.005\n",
      "iteration: 1750 loss: 0.0085 lr: 0.005\n",
      "iteration: 2000 loss: 0.0087 lr: 0.005\n",
      "iteration: 2250 loss: 0.0079 lr: 0.005\n",
      "iteration: 2500 loss: 0.0078 lr: 0.005\n",
      "iteration: 2750 loss: 0.0079 lr: 0.005\n",
      "iteration: 3000 loss: 0.0075 lr: 0.005\n",
      "iteration: 3250 loss: 0.0071 lr: 0.005\n",
      "iteration: 3500 loss: 0.0068 lr: 0.005\n",
      "iteration: 3750 loss: 0.0070 lr: 0.005\n",
      "iteration: 4000 loss: 0.0071 lr: 0.005\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file, displayiters=250, saveiters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['AVA', 'neuron1', 'neuron2', 'neuron3'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Chip_with_WBFM_hardware_z8Oct12/Chip_with_WBFM_hardware_z8_Charlie95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/users/charles.fieseler/.conda/envs/DLC-GPU/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Chip_with_WBFM_hardware_z8Oct12/Documentation_data-Chip_with_WBFM_hardware_z8_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/dlc-models/iteration-0/Chip_with_WBFM_hardware_z8Oct12-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_Chip_with_WBFM_hardware_z8Oct12shuffle1_5000  with # of trainingiterations: 5000\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from /users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/dlc-models/iteration-0/Chip_with_WBFM_hardware_z8Oct12-trainset95shuffle1/train/snapshot-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 12.87it/s]\n",
      " 40%|████      | 2/5 [00:00<00:00, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-5000\n",
      "Results for 5000  training iterations: 95 1 train error: 1.99 pixels. Test error: 1.69  pixels.\n",
      "With pcutoff of 0.6  train error: 1.99 pixels. Test error: 1.69 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 14.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['AVA', 'neuron1', 'neuron2', 'neuron3'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Chip_with_WBFM_hardware_z8Oct12/Chip_with_WBFM_hardware_z8_Charlie95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/users/charles.fieseler/.conda/envs/DLC-GPU/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Chip_with_WBFM_hardware_z8Oct12/Documentation_data-Chip_with_WBFM_hardware_z8_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/dlc-models/iteration-0/Chip_with_WBFM_hardware_z8Oct12-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-5000 for model /users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/dlc-models/iteration-0/Chip_with_WBFM_hardware_z8Oct12-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from /users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/dlc-models/iteration-0/Chip_with_WBFM_hardware_z8Oct12-trainset95shuffle1/train/snapshot-5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/videos/27082020_trial2_HEAD_500frames_mcherry_slice8.avi\n",
      "Loading  /users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/videos/27082020_trial2_HEAD_500frames_mcherry_slice8.avi\n",
      "Duration of video [s]:  50.0 , recorded with  10.0 fps!\n",
      "Overall # of frames:  500  found with (before cropping) frame dimensions:  332 132\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "510it [00:02, 233.09it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  500\n",
      "Saving results in /users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/videos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_Chip_with_WBFM_hardware_z8Oct12shuffle1_5000'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "deeplabcut.analyze_videos(path_config_file,[video_fname], videotype='.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. \n",
    "\n",
    "THIS HAS MANY FUN OPTIONS! \n",
    "\n",
    "``deeplabcut.create_labeled_video(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, filtered=False, save_frames=False, Frames2plot=None, delete=False, displayedbodyparts='all', codec='mp4v', outputframerate=None, destfolder=None, draw_skeleton=False, trailpoints=0, displaycropped=False)``\n",
    "\n",
    "So please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/videos ['/users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/videos/27082020_trial2_HEAD_500frames_mcherry_slice8.avi']\n",
      "Loading  /users/charles.fieseler/DLC_for_WBFM/DLC_Projects/Chip_with_WBFM_hardware_z8-Charlie-2020-10-12/videos/27082020_trial2_HEAD_500frames_mcherry_slice8.avi and data.\n",
      "500\n",
      "Duration of video [s]:  50.0 , recorded with  10.0 fps!\n",
      "Overall # of frames:  500 with cropped frame dimensions:  332 132\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 1112.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# video_fname = os.path.join(project_folder, 'videos/27082020_trial2_HEAD_500frames_mcherry_slice8.avi')\n",
    "\n",
    "deeplabcut.create_labeled_video(path_config_file,[video_fname])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [optional step]\n",
    "\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. This step has many options, so please look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file,['/videos/video3.avi']) #pass a specific video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Afterwards, if you want to look at the adjusted frames, you can load them in the main GUI by running: ``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "(you can add a new \"cell\" below to add this code!)\n",
    "\n",
    "#### Once all folders are relabeled, check the labels again! If you are not happy, adjust them in the main GUI:\n",
    "\n",
    "``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "Check Labels:\n",
    "\n",
    "``deeplabcut.check_labels(path_config_file)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [],
   "source": [
    "#NOW, merge this with your original data:\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refinement of labels and appending them to the original dataset, this creates a new iteration of training dataset. This is automatically set in the config.yaml file, so let's get training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-DLC-CPU-dev]",
   "language": "python",
   "name": "conda-env-.conda-DLC-CPU-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
