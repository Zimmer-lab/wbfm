{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DeepLabCut Toolbox\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "\n",
    "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
    "This shows the most simple code to do so, but many of the functions have additional features, so please check out the overview & the protocol paper!\n",
    "\n",
    "This notebook illustrates how to:\n",
    "- create a project\n",
    "- extract training frames\n",
    "- label the frames\n",
    "- plot the labeled images\n",
    "- create a training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- analyze a novel video\n",
    "- create an automatically labeled video \n",
    "- plot the trajectories\n",
    "\n",
    "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
    "\n",
    "This shows the most simple code to do so, but many of the functions have additional features, so please check out the overview & the protocol paper!\n",
    "\n",
    "Nath\\*, Mathis\\* et al.: Using DeepLabCut for markerless pose estimation during behavior across species. Nature Protocols, 2019.\n",
    "\n",
    "Paper: https://www.nature.com/articles/s41596-019-0176-0\n",
    "\n",
    "Pre-print: https://www.biorxiv.org/content/biorxiv/early/2018/11/24/476531.full.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: this is for use with 3d slices of data in Zimmer lab format \n",
    "\n",
    "This is for use with real WBFM data; for now I don't have annotations, and am just going to make sure the pipeline works for extracting volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "It is always good idea to keep the projects seperate if you want to use different networks to analze your data. You should use one project if you are tracking similar subjects/items even if in different environments. This function creates a new project with sub-directories and a basic configuration file in the user defined directory otherwise the project is created in the current working directory.\n",
    "\n",
    "You can always add new videos (for lableing more data) to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLClight=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "%env DLClight=True\n",
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [],
   "source": [
    "task='WormTest' # Enter the name of your experiment Task\n",
    "experimenter='Charlie' # Enter the name of the experimenter\n",
    "#video=['wb_immobilized/KU20170626-TKU721_nostim_ctrl_w2_part1.ome.tiff'] # Enter the paths of your videos OR FOLDER you want to grab frames from.\n",
    "# video=['/groups/zimmer/Ulises/wbfm/wbfm_december2018/20181220/data/worm1/mCherry/ome']\n",
    "video=['/users/charles.fieseler/test_worm1_data/mCherry/']\n",
    "\n",
    "# path_config_file=deeplabcut.create_new_project(task,experimenter,video,copy_videos=False, videotype='.tiff') \n",
    "\n",
    "# NOTE: The function returns the path, where your project is. \n",
    "# You could also enter this manually (e.g. if the project is already created and you want to pick up, where you stopped...)\n",
    "# path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-22/config.yaml'\n",
    "path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/config.yaml'\n",
    "# path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-25/config.yaml'\n",
    "#path_config_file = 'C:\\\\Users\\\\charl\\\\Documents\\\\Current_work\\\\DeepLabCut_etc\\\\DeepLabCut-fork\\\\examples\\\\WormTest-Charlie-2020-05-21\\\\config.yaml' # Enter the path of the config file that was just created from the above step (check the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deeplabcut.create_new_project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/config.yaml\n"
     ]
    }
   ],
   "source": [
    "print(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save individual volumes from ome.tiff movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Basically this is a custom extract_frames() function\n",
    "#\n",
    "\n",
    "from pathlib import Path\n",
    "from deeplabcut.utils import auxiliaryfunctions\n",
    "import tifffile\n",
    "import platform\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_volumes_from_many_files(path_config_file, which_vol=None):\n",
    "    \"\"\"\n",
    "    Assumes a folder of many different volumes, and copies some in the folder given by 'out_folder'\n",
    "    \"\"\"\n",
    "    \n",
    "    if platform.system() is 'Windows':\n",
    "        is_windows = True\n",
    "    else:\n",
    "        is_windows = False\n",
    "    \n",
    "    config_file = Path(path_config_file).resolve()\n",
    "    cfg = auxiliaryfunctions.read_config(config_file)\n",
    "    print(\"Config file read successfully.\")\n",
    "    \n",
    "    video_fnames = [i for i in cfg['video_sets'].keys()]\n",
    "    print(type(video_fnames))\n",
    "    print(\"Found {} volumes.\".format(len(video_fnames)))\n",
    "    \n",
    "    # Read basic metadata\n",
    "    \n",
    "    # Get volume indices to save\n",
    "    if which_vol is None:\n",
    "        which_vol = [0]\n",
    "    \n",
    "    for i_vol in which_vol:\n",
    "        print(\"Reading volume {}/{}\".format(i_vol, len(which_vol)))\n",
    "        \n",
    "        this_fname = video_fnames[i_vol]\n",
    "\n",
    "        # Read and make output name\n",
    "        this_volume = tifffile.imread(this_fname)\n",
    "        output_name = 'img{}.tif'.format(i_vol)\n",
    "\n",
    "        # Save in output folder\n",
    "        fname = Path(video_fnames[0])\n",
    "        output_path = os.path.join(Path(path_config_file).parents[0],'labeled-data',fname.stem)\n",
    "\n",
    "        tifffile.imsave(os.path.join(str(output_path),output_name), this_volume)\n",
    "\n",
    "        print('Saved volume to {}\\\\{}'.format(output_path, output_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "        \n",
    "def extract_volumes_from_MATLAB_output(path_config_file, which_vol=None):\n",
    "    \"\"\"\n",
    "    Takes a video filename, which is a large ome-tiff file, and saves a volume in the folder given by 'out_folder'\n",
    "    \"\"\"\n",
    "    \n",
    "    if platform.system() is 'Windows':\n",
    "        is_windows = True\n",
    "    else:\n",
    "        is_windows = False\n",
    "    \n",
    "    config_file = Path(path_config_file).resolve()\n",
    "    cfg = auxiliaryfunctions.read_config(config_file)\n",
    "    print(\"Config file read successfully.\")\n",
    "    \n",
    "    video_fname = [i for i in cfg['video_sets'].keys()][0] # Assume one video for now (will be giant, ~3GB)\n",
    "    print(video_fname)\n",
    "    \n",
    "    # Read basic metadata to get 'nz' and 'nt'\n",
    "    with tifffile.TiffFile(video_fname) as vid:\n",
    "        #print(tifffile.xml2dict(vid.ome_metadata))\n",
    "        print(vid.ome_metadata)\n",
    "        ome_metadata = vid.ome_metadata\n",
    "        if isinstance(ome_metadata, str):\n",
    "            # Appears to be a bug that just returns a string... can fix manually though\n",
    "            ome_metadata = tifffile.xml2dict(ome_metadata)['OME']\n",
    "        print(ome_metadata.keys())\n",
    "        mdat = ome_metadata['Image']['Pixels']\n",
    "        nz, nt = mdat['SizeZ'], mdat['SizeT']\n",
    "    \n",
    "    # Get volume indices to save\n",
    "    if which_vol is None:\n",
    "        which_vol = [0]\n",
    "    \n",
    "    for i_vol in which_vol:\n",
    "        print(\"Read volume {}/{}\".format(i_vol, len(which_vol)))\n",
    "        \n",
    "        # Convert scalar volume label to the sequential frames\n",
    "        # Note: this may change for future input videos!\n",
    "        vol_indices = list(range(i_vol*nz, i_vol*nz + nz))\n",
    "\n",
    "        # Read and make output name\n",
    "        this_volume = tifffile.imread(video_fname, key=vol_indices)\n",
    "        output_name = 'img{}.tif'.format(i_vol)\n",
    "\n",
    "        # Save in output folder\n",
    "        fname = Path(video_fname)\n",
    "        output_path = os.path.join(Path(path_config_file).parents[0],'labeled-data',fname.stem)\n",
    "\n",
    "        tifffile.imsave(os.path.join(str(output_path),output_name), this_volume)\n",
    "\n",
    "        print('Saved volume to {}\\\\{}'.format(output_path, output_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "        \n",
    "def extract_volumes_from_charlie_output(path_config_file, nz, which_vol=None):\n",
    "    \"\"\"\n",
    "    Takes a video filename, which is a large ome-tiff file, and saves a volume in the folder given by 'out_folder'\n",
    "    \"\"\"\n",
    "    \n",
    "    config_file = Path(path_config_file).resolve()\n",
    "    cfg = auxiliaryfunctions.read_config(config_file)\n",
    "    print(\"Config file read successfully.\")\n",
    "    \n",
    "    video_fname = [i for i in cfg['video_sets'].keys()][0] # Assume one video for now (will be giant, ~3GB)\n",
    "    print(video_fname)\n",
    "    \n",
    "    # Get volume indices to save\n",
    "    if which_vol is None:\n",
    "        which_vol = [0]\n",
    "    \n",
    "    for i_vol in which_vol:\n",
    "        print(\"Reading volume {}/{}\".format(i_vol, len(which_vol)-1))\n",
    "        \n",
    "        # Convert scalar volume label to the sequential frames\n",
    "        # Note: this may change for future input videos!\n",
    "        vol_indices = list(range(i_vol*nz, i_vol*nz + nz))\n",
    "        print(\"Converted volume indices: {} to {} (not including last frame)\".format(i_vol*nz, i_vol*nz + nz))\n",
    "\n",
    "        # Read and make output name\n",
    "        this_volume = tifffile.imread(video_fname, key=vol_indices)\n",
    "        output_name = 'img{}.tif'.format(i_vol)\n",
    "\n",
    "        # Save in output folder\n",
    "        fname = Path(video_fname)\n",
    "        output_path = os.path.join(Path(path_config_file).parents[0],'labeled-data',fname.stem)\n",
    "\n",
    "        tifffile.imsave(os.path.join(str(output_path),output_name), this_volume)\n",
    "\n",
    "        print('Saved volume to {}'.format(os.path.join(output_path, output_name)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "/users/charles.fieseler/test_worm1_data/mCherry/test_100frames.ome.tiff\n",
      "Reading volume 0/4\n",
      "Converted volume indices: 0 to 39 (not including last frame)\n",
      "Saved volume to /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome/img0.tif\n",
      "Reading volume 1/4\n",
      "Converted volume indices: 39 to 78 (not including last frame)\n",
      "Saved volume to /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome/img1.tif\n",
      "Reading volume 2/4\n",
      "Converted volume indices: 78 to 117 (not including last frame)\n",
      "Saved volume to /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome/img2.tif\n",
      "Reading volume 3/4\n",
      "Converted volume indices: 117 to 156 (not including last frame)\n",
      "Saved volume to /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome/img3.tif\n",
      "Reading volume 4/4\n",
      "Converted volume indices: 156 to 195 (not including last frame)\n",
      "Saved volume to /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome/img4.tif\n"
     ]
    }
   ],
   "source": [
    "extract_volumes_from_charlie_output(path_config_file, 39, list(range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separately: Manually do BCPD to create the annotations!\n",
    "\n",
    "For now, is completely separate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatically update the config file\n",
    "\n",
    "# TODO; use edit_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def bpcd_tracker2config_names(path_config_file):\n",
    "    \"\"\"\n",
    "    Automatically updates the config file with the proper number of neurons, and deletes any other default bodyparts.\n",
    "    Only affects the \"bodyparts\" field\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get number of neurons from annotations\n",
    "    home = os.path.dirname(path_config_file)\n",
    "    # TODO: hardcoded folder\n",
    "    annotations_fname = os.path.join(home,'labeled-data', 'test_100frames.ome','CollectedData_Charlie.csv')\n",
    "    df = pd.read_csv(annotations_fname)\n",
    "    num_neurons = int(df.shape[1] / 3)\n",
    "    print(\"Adding body part annotations for {} neurons\".format(num_neurons))\n",
    "#     error()\n",
    "    \n",
    "    # Read in entire config file into a list\n",
    "    config_rows = []\n",
    "    with open(path_config_file) as config:\n",
    "        c_reader = csv.reader(config)#, delimiter=' ')\n",
    "        for row in c_reader:\n",
    "            config_rows.append(row)\n",
    "    \n",
    "    ## Delete the current bodypart lines\n",
    "    delete_these_rows = False\n",
    "    config_rows_edit = config_rows.copy()\n",
    "    for row in config_rows:\n",
    "        if row == ['bodyparts:']:\n",
    "            delete_these_rows = True # Start deleting next row\n",
    "        elif row == ['start: 0']:\n",
    "            delete_these_rows = False # Do not delete this row, or others\n",
    "            break\n",
    "        elif delete_these_rows == True:\n",
    "            # Don't delete either of the two above, but only in between those rows\n",
    "            config_rows_edit.remove(row)\n",
    "    \n",
    "    ## Add in the named neuron lines\n",
    "    # Using \"list slicing\" https://www.geeksforgeeks.org/python-insert-list-in-another-list/\n",
    "    new_names = [['- neuron{}'.format(i)] for i in range(num_neurons)]\n",
    "    insert_index = config_rows_edit.index(['start: 0'])\n",
    "    config_rows_edit[insert_index:insert_index] = new_names\n",
    "    \n",
    "    ## Write the file again\n",
    "    if True:\n",
    "        with open(path_config_file, 'w', newline='') as config:\n",
    "            c_writer = csv.writer(config)\n",
    "            for row in config_rows_edit:\n",
    "                c_writer.writerow(row)\n",
    "    \n",
    "    print(\"Finished! Check the config.yaml file to make sure the bodyparts are properly written\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def wb_tracker2config_names(path_config_file):\n",
    "    \"\"\"\n",
    "    Automatically updates the config file with the proper number of neurons, and deletes any other default bodyparts.\n",
    "    Only affects the \"bodyparts\" field\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get number of neurons from annotations\n",
    "    home = os.path.dirname(path_config_file)\n",
    "    # TODO: hardcoded folder\n",
    "    annotations_fname = os.path.join(home,'labeled-data', 'my-test-annotations','CollectedData_Charlie.csv')\n",
    "#     with h5py.File(annotations_fname, 'r') as ann:\n",
    "#         k = list(ann['df_with_missing']['table'].keys())\n",
    "#         print(k)\n",
    "#         num_neurons = int(len(ann[k[0]])/3)\n",
    "    df = pd.read_csv(annotations_fname)\n",
    "    num_neurons = int(df.shape[1] / 3)\n",
    "    print(\"Adding body part annotations for {} neurons\".format(num_neurons))\n",
    "#     error()\n",
    "    \n",
    "    # Read in entire config file into a list\n",
    "    config_rows = []\n",
    "    with open(path_config_file) as config:\n",
    "        c_reader = csv.reader(config)#, delimiter=' ')\n",
    "        for row in c_reader:\n",
    "            config_rows.append(row)\n",
    "    \n",
    "    ## Delete the current bodypart lines\n",
    "    delete_these_rows = False\n",
    "    config_rows_edit = config_rows.copy()\n",
    "    for row in config_rows:\n",
    "        if row == ['bodyparts:']:\n",
    "            delete_these_rows = True # Start deleting next row\n",
    "        elif row == ['start: 0']:\n",
    "            delete_these_rows = False # Do not delete this row, or others\n",
    "            break\n",
    "        elif delete_these_rows == True:\n",
    "            # Don't delete either of the two above, but only in between those rows\n",
    "            config_rows_edit.remove(row)\n",
    "    \n",
    "    ## Add in the named neuron lines\n",
    "    # Using \"list slicing\" https://www.geeksforgeeks.org/python-insert-list-in-another-list/\n",
    "    new_names = [['- neuron{}'.format(i)] for i in range(num_neurons)]\n",
    "    insert_index = config_rows_edit.index(['start: 0'])\n",
    "    config_rows_edit[insert_index:insert_index] = new_names\n",
    "    \n",
    "    ## Write the file again\n",
    "    if True:\n",
    "        with open(path_config_file, 'w', newline='') as config:\n",
    "            c_writer = csv.writer(config)\n",
    "            for row in config_rows_edit:\n",
    "                c_writer.writerow(row)\n",
    "    #for row in config_rows_edit:\n",
    "        #c_writer.writerow(row)\n",
    "     #   print(row[:])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding body part annotations for 34 neurons\n",
      "Finished! Check the config.yaml file to make sure the bodyparts are properly written\n"
     ]
    }
   ],
   "source": [
    "bpcd_tracker2config_names(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "## Check the labels\n",
    "\n",
    "[OPTIONAL] Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. The DeepLabCut toolbox provides a function `check\\_labels'  to do so. It is used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLClight=True\n"
     ]
    }
   ],
   "source": [
    "%env DLClight=True\n",
    "import deeplabcut\n",
    "# path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/config.yaml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by Charlie.\n",
      "Debug; reading from files:  Index(['/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome/img0.tif',\n",
      "       '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome/img1.tif',\n",
      "       '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome/img2.tif',\n",
      "       '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome/img3.tif',\n",
      "       '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome/img4.tif'],\n",
      "      dtype='object')\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/labeled-data/test_100frames.ome_labeled  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use relauch the labeling GUI to move them around, save, and re-plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "\n",
    "This function generates the training data information for network training based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles if they want to benchmark the performance (typcailly, 1 is what you will set, so you pass nothing!). \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**. For most all use cases we have seen, the defaults are perfectly fine.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLClight=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "# IF THE KERNEL IS RESET\n",
    "%env DLClight=True\n",
    "import deeplabcut\n",
    "path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/config.yaml'\n",
    "# path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-22/config.yaml'\n",
    "#path_config_file = 'C:\\\\Users\\\\charl\\\\Documents\\\\Current_work\\\\DeepLabCut_etc\\\\DeepLabCut-fork\\\\examples\\\\WormTest-Charlie-2020-05-21\\\\config.yaml' # Enter the path of the config file that was just created from the above step (check the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized z-slice training data; using custom function\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95, 1, (array([4, 3, 0, 1]), array([2])))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "#remember, there are several networks you can pick, the default is resnet-50!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training:\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18],\n",
      "                [19],\n",
      "                [20],\n",
      "                [21],\n",
      "                [22],\n",
      "                [23],\n",
      "                [24],\n",
      "                [25],\n",
      "                [26],\n",
      "                [27],\n",
      "                [28],\n",
      "                [29],\n",
      "                [30],\n",
      "                [31],\n",
      "                [32],\n",
      "                [33]],\n",
      " 'all_joints_names': ['neuron0',\n",
      "                      'neuron1',\n",
      "                      'neuron2',\n",
      "                      'neuron3',\n",
      "                      'neuron4',\n",
      "                      'neuron5',\n",
      "                      'neuron6',\n",
      "                      'neuron7',\n",
      "                      'neuron8',\n",
      "                      'neuron9',\n",
      "                      'neuron10',\n",
      "                      'neuron11',\n",
      "                      'neuron12',\n",
      "                      'neuron13',\n",
      "                      'neuron14',\n",
      "                      'neuron15',\n",
      "                      'neuron16',\n",
      "                      'neuron17',\n",
      "                      'neuron18',\n",
      "                      'neuron19',\n",
      "                      'neuron20',\n",
      "                      'neuron21',\n",
      "                      'neuron22',\n",
      "                      'neuron23',\n",
      "                      'neuron24',\n",
      "                      'neuron25',\n",
      "                      'neuron26',\n",
      "                      'neuron27',\n",
      "                      'neuron28',\n",
      "                      'neuron29',\n",
      "                      'neuron30',\n",
      "                      'neuron31',\n",
      "                      'neuron32',\n",
      "                      'neuron33'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': False,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-1/UnaugmentedDataSet_WormTestJun30/WormTest_Charlie95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 1.0,\n",
      " 'init_weights': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-1/UnaugmentedDataSet_WormTestJun30/Documentation_data-WormTest_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.001, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 34,\n",
      " 'num_z_slices': 13,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 3,\n",
      " 'project_path': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 1.0,\n",
      " 'scale_jitter_up': 1.0,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/dlc-models/iteration-1/WormTestJun30-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'using_z_slices': True,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Switching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\n",
      "Starting with standard pose-dataset loader.\n",
      "Initializing PoseNetSlices\n",
      "Creating new class for use with z-slice data, PoseNetSlices\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Display_iters overwritten as 100\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'using_z_slices': True, 'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/dlc-models/iteration-1/WormTestJun30-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 1.0, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'weigh_only_present_joints': False, 'pairwise_huber_loss': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'crop': False, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25], [26], [27], [28], [29], [30], [31], [32], [33]], 'all_joints_names': ['neuron0', 'neuron1', 'neuron2', 'neuron3', 'neuron4', 'neuron5', 'neuron6', 'neuron7', 'neuron8', 'neuron9', 'neuron10', 'neuron11', 'neuron12', 'neuron13', 'neuron14', 'neuron15', 'neuron16', 'neuron17', 'neuron18', 'neuron19', 'neuron20', 'neuron21', 'neuron22', 'neuron23', 'neuron24', 'neuron25', 'neuron26', 'neuron27', 'neuron28', 'neuron29', 'neuron30', 'neuron31', 'neuron32', 'neuron33'], 'dataset': 'training-datasets/iteration-1/UnaugmentedDataSet_WormTestJun30/WormTest_Charlie95shuffle1.mat', 'display_iters': 1000, 'init_weights': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-1/UnaugmentedDataSet_WormTestJun30/Documentation_data-WormTest_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.001, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 34, 'pos_dist_thresh': 3, 'project_path': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30', 'save_iters': 50000, 'scale_jitter_lo': 1.0, 'scale_jitter_up': 1.0, 'num_z_slices': 13, 'output_stride': 16, 'deconvolutionstride': 2}\n",
      "Starting training....\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Image width 320 and height 244 should be divisible by block_size: 3\n\t [[node pose/locref_pred/map/while/SpaceToDepth (defined at /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py:73) ]]\n\t [[{{node GroupCrossDeviceControlEdges_0/absolute_difference/weighted_loss/num_present/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_7}}]]\n\nCaused by op 'pose/locref_pred/map/while/SpaceToDepth', defined at:\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 597, in start\n    self.io_loop.start()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-56b077e42ab3>\", line 1, in <module>\n    deeplabcut.train_network(path_config_file, displayiters=100, saveiters=1000)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\", line 189, in train_network\n    allow_growth=allow_growth,\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/train.py\", line 184, in train\n    losses = pose_net(cfg).train(batch)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 229, in train\n    heads = self.get_net(batch[Batch.inputs])\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 156, in get_net\n    return self.prediction_layers(net, end_points, block_size=block_size)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 140, in prediction_layers\n    cfg.num_joints * 2, block_size=block_size)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 36, in prediction_layer\n    pred5d = expand_depth(pred4d, block_size)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 74, in expand_depth\n    end_points4d_ch_first)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 497, in map_fn\n    maximum_iterations=n)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3556, in while_loop\n    return_same_structure)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3087, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3022, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3525, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 486, in compute\n    packed_fn_values = fn(packed_values)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 73, in <lambda>\n    end_points5d_ch_first = tf.map_fn(lambda x: tf.space_to_depth(x,block_size),\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2686, in space_to_depth\n    return gen_array_ops.space_to_depth(input, block_size, data_format, name=name)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8812, in space_to_depth\n    data_format=data_format, name=name)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Image width 320 and height 244 should be divisible by block_size: 3\n\t [[node pose/locref_pred/map/while/SpaceToDepth (defined at /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py:73) ]]\n\t [[{{node GroupCrossDeviceControlEdges_0/absolute_difference/weighted_loss/num_present/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_7}}]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Image width 320 and height 244 should be divisible by block_size: 3\n\t [[{{node pose/locref_pred/map/while/SpaceToDepth}}]]\n\t [[{{node GroupCrossDeviceControlEdges_0/absolute_difference/weighted_loss/num_present/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_7}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-56b077e42ab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             )  # pass on path and file name for pose_cfg.yaml!\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    263\u001b[0m         [_, loss_val, summary] = sess.run(\n\u001b[1;32m    264\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_lr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         )\n\u001b[1;32m    267\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Image width 320 and height 244 should be divisible by block_size: 3\n\t [[node pose/locref_pred/map/while/SpaceToDepth (defined at /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py:73) ]]\n\t [[{{node GroupCrossDeviceControlEdges_0/absolute_difference/weighted_loss/num_present/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_7}}]]\n\nCaused by op 'pose/locref_pred/map/while/SpaceToDepth', defined at:\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/traitlets/config/application.py\", line 664, in launch_instance\n    app.start()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 597, in start\n    self.io_loop.start()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 787, in inner\n    self.run()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n    yield self.process_one()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 714, in __init__\n    self.run()\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n    user_expressions, allow_stdin,\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2858, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2886, in _run_cell\n    return runner(coro)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3063, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3254, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-56b077e42ab3>\", line 1, in <module>\n    deeplabcut.train_network(path_config_file, displayiters=100, saveiters=1000)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/training.py\", line 189, in train_network\n    allow_growth=allow_growth,\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/train.py\", line 184, in train\n    losses = pose_net(cfg).train(batch)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 229, in train\n    heads = self.get_net(batch[Batch.inputs])\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 156, in get_net\n    return self.prediction_layers(net, end_points, block_size=block_size)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 140, in prediction_layers\n    cfg.num_joints * 2, block_size=block_size)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 36, in prediction_layer\n    pred5d = expand_depth(pred4d, block_size)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 74, in expand_depth\n    end_points4d_ch_first)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 497, in map_fn\n    maximum_iterations=n)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3556, in while_loop\n    return_same_structure)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3087, in BuildLoop\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3022, in _BuildLoop\n    body_result = body(*packed_vars_for_body)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3525, in <lambda>\n    body = lambda i, lv: (i + 1, orig_body(*lv))\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 486, in compute\n    packed_fn_values = fn(packed_values)\n  File \"/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py\", line 73, in <lambda>\n    end_points5d_ch_first = tf.map_fn(lambda x: tf.space_to_depth(x,block_size),\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2686, in space_to_depth\n    return gen_array_ops.space_to_depth(input, block_size, data_format, name=name)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 8812, in space_to_depth\n    data_format=data_format, name=name)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/users/charles.fieseler/.conda/envs/DLC-GPU-dev/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Image width 320 and height 244 should be divisible by block_size: 3\n\t [[node pose/locref_pred/map/while/SpaceToDepth (defined at /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/nnet/pose_net_slices.py:73) ]]\n\t [[{{node GroupCrossDeviceControlEdges_0/absolute_difference/weighted_loss/num_present/broadcast_weights/assert_broadcastable/AssertGuard/Assert/data_7}}]]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(path_config_file, displayiters=100, saveiters=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DLClight=True\n"
     ]
    }
   ],
   "source": [
    "# IF THE KERNEL IS RESET\n",
    "%env DLClight=True\n",
    "import deeplabcut\n",
    "path_config_file = '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/config.yaml'\n",
    "\n",
    "#path_config_file = 'C:\\\\Users\\\\charl\\\\Documents\\\\Current_work\\\\DeepLabCut_etc\\\\DeepLabCut-fork\\\\examples\\\\WormTest-Charlie-2020-05-21\\\\config.yaml' # Enter the path of the config file that was just created from the above step (check the folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18],\n",
      "                [19],\n",
      "                [20],\n",
      "                [21],\n",
      "                [22],\n",
      "                [23],\n",
      "                [24],\n",
      "                [25],\n",
      "                [26],\n",
      "                [27],\n",
      "                [28],\n",
      "                [29],\n",
      "                [30],\n",
      "                [31],\n",
      "                [32],\n",
      "                [33]],\n",
      " 'all_joints_names': ['neuron0',\n",
      "                      'neuron1',\n",
      "                      'neuron2',\n",
      "                      'neuron3',\n",
      "                      'neuron4',\n",
      "                      'neuron5',\n",
      "                      'neuron6',\n",
      "                      'neuron7',\n",
      "                      'neuron8',\n",
      "                      'neuron9',\n",
      "                      'neuron10',\n",
      "                      'neuron11',\n",
      "                      'neuron12',\n",
      "                      'neuron13',\n",
      "                      'neuron14',\n",
      "                      'neuron15',\n",
      "                      'neuron16',\n",
      "                      'neuron17',\n",
      "                      'neuron18',\n",
      "                      'neuron19',\n",
      "                      'neuron20',\n",
      "                      'neuron21',\n",
      "                      'neuron22',\n",
      "                      'neuron23',\n",
      "                      'neuron24',\n",
      "                      'neuron25',\n",
      "                      'neuron26',\n",
      "                      'neuron27',\n",
      "                      'neuron28',\n",
      "                      'neuron29',\n",
      "                      'neuron30',\n",
      "                      'neuron31',\n",
      "                      'neuron32',\n",
      "                      'neuron33'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-1/UnaugmentedDataSet_WormTestJun30/WormTest_Charlie95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-1/UnaugmentedDataSet_WormTestJun30/Documentation_data-WormTest_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.001, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 34,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 3,\n",
      " 'project_path': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/dlc-models/iteration-1/WormTestJun30-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/evaluation-results/  already exists!\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-30/evaluation-results/iteration-1/WormTestJun30-trainset95shuffle1  already exists!\n",
      "Running  DLC_resnet50_WormTestJun30shuffle1_12000  with # of trainingiterations: 12000\n",
      "Initializing ResNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00,  8.85it/s]\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/evaluate.py:857: RuntimeWarning: Mean of empty slice\n",
      "  RMSEpcutoff.iloc[testIndices].values.flatten()\n",
      "/users/charles.fieseler/DeepLabCut-dev/DeepLabCut/deeplabcut/pose_estimation_tensorflow/evaluate.py:860: RuntimeWarning: Mean of empty slice\n",
      "  RMSEpcutoff.iloc[trainIndices].values.flatten()\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-12000\n",
      "Results for 12000  training iterations: 95 1 train error: 358.75 pixels. Test error: 379.51  pixels.\n",
      "With pcutoff of 0.6  train error: nan pixels. Test error: nan pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(path_config_file, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-11000 for model /users/charles.fieseler/DeepLabCut-dev/DeepLabCut/examples/WormTest-Charlie-2020-06-12/dlc-models/iteration-0/WormTestJun12-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "No video(s) were found. Please check your paths and/or 'video_type'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_WormTestJun12shuffle1_11000'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videofile_path = ['videos/video3.avi','videos/video4.avi'] #Enter a folder OR a list of videos to analyze.\n",
    "\n",
    "deeplabcut.analyze_videos(path_config_file,videofile_path, videotype='.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [optional step]\n",
    "\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. This step has many options, so please look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file,['/videos/video3.avi']) #pass a specific video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [],
   "source": [
    "%gui wx\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Afterwards, if you want to look at the adjusted frames, you can load them in the main GUI by running: ``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "(you can add a new \"cell\" below to add this code!)\n",
    "\n",
    "#### Once all folders are relabeled, check the labels again! If you are not happy, adjust them in the main GUI:\n",
    "\n",
    "``deeplabcut.label_frames(path_config_file)``\n",
    "\n",
    "Check Labels:\n",
    "\n",
    "``deeplabcut.check_labels(path_config_file)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [],
   "source": [
    "#NOW, merge this with your original data:\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refinement of labels and appending them to the original dataset, this creates a new iteration of training dataset. This is automatically set in the config.yaml file, so let's get training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. \n",
    "\n",
    "THIS HAS MANY FUN OPTIONS! \n",
    "\n",
    "``deeplabcut.create_labeled_video(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, filtered=False, save_frames=False, Frames2plot=None, delete=False, displayedbodyparts='all', codec='mp4v', outputframerate=None, destfolder=None, draw_skeleton=False, trailpoints=0, displaycropped=False)``\n",
    "\n",
    "So please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:.conda-DLC-GPU-dev]",
   "language": "python",
   "name": "conda-env-.conda-DLC-GPU-dev-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
