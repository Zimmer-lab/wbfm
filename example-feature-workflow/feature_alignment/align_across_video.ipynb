{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from DLC_for_WBFM.utils.feature_detection.utils_features import *\n",
    "from DLC_for_WBFM.utils.feature_detection.utils_tracklets import *\n",
    "from DLC_for_WBFM.utils.feature_detection.utils_detection import *\n",
    "from DLC_for_WBFM.utils.feature_detection.visualization_tracks import *\n",
    "from DLC_for_WBFM.utils.video_and_data_conversion.import_video_as_array import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 3d bigtiff folder\n",
    "bigtiff_folder = r'D:\\More-stabilized-wbfm'\n",
    "\n",
    "# Will get traces from two videos:\n",
    "btf_fname_red = r'test2020-10-22_16-15-20_test4-channel-0-pco_camera1\\test2020-10-22_16-15-20_test4-channel-0-pco_camera1bigtiff.btf'\n",
    "btf_fname_red = os.path.join(bigtiff_folder, btf_fname_red)\n",
    "#btf_fname_green = r'test2020-10-22_16-15-20_test4-channel-1-pco_camera2\\test2020-10-22_16-15-20_test4-channel-1-pco_camera2bigtiff.btf'\n",
    "#btf_fname_green = os.path.join(bigtiff_folder, btf_fname_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol0 = get_single_volume(btf_fname_red, 0, num_slices=33, alpha=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.15\n",
    "dat_foldername = r'..\\point_cloud_alignment'\n",
    "fname = os.path.join(dat_foldername, 'img100.tif')\n",
    "f = lambda tif : (alpha*tif.asarray()).astype('uint8')\n",
    "with tifffile.TiffFile(fname) as tif0:\n",
    "    vol0_old = f(tif0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use single function to track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DLC_for_WBFM.utils.feature_detection.feature_pipeline import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "Matching frames 100 and 101 (end at 110)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.2) C:\\Miniconda3\\conda-bld\\opencv-suite_1534379934306\\work\\modules\\core\\src\\batch_distance.cpp:238: error: (-215:Assertion failed) type == src2.type() && src1.cols == src2.cols && (type == 5 || type == 0) in function 'cv::batchDistance'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3aa19c8f0dde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                              \u001b[0mnum_slices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                              \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                              verbose=2)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\charles.fieseler\\documents\\current_work\\dlc_for_wbfm\\DLC_for_WBFM\\utils\\feature_detection\\feature_pipeline.py\u001b[0m in \u001b[0;36mtrack_neurons_full_video\u001b[1;34m(vid_fname, start_frame, num_frames, num_slices, alpha, verbose)\u001b[0m\n\u001b[0;32m     75\u001b[0m                                                   \u001b[0mdat1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                                                   \u001b[0mnum_slices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_slices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                                                   verbose=verbose-1)\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mall_matches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mall_conf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\charles.fieseler\\documents\\current_work\\dlc_for_wbfm\\DLC_for_WBFM\\utils\\feature_detection\\feature_pipeline.py\u001b[0m in \u001b[0;36mtrack_neurons_two_volumes\u001b[1;34m(dat0, dat1, num_slices, verbose)\u001b[0m\n\u001b[0;32m     31\u001b[0m            \u001b[1;34m'kp0'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mneurons0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m            'kp1':neurons1}\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mall_f0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_f1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_features_on_all_planes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdat1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Now, match the neurons using feature space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\charles.fieseler\\documents\\current_work\\dlc_for_wbfm\\DLC_for_WBFM\\utils\\feature_detection\\utils_features.py\u001b[0m in \u001b[0;36mbuild_features_on_all_planes\u001b[1;34m(dat0, dat1, verbose, start_plane, detect_keypoints, kp0, kp1, sz, num_features_per_plane, matches_to_keep, dat_foldername)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[0mim1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdat1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdetect_keypoints\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[0mkeypoints0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeypoints1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_features_and_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features_per_plane\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatches_to_keep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[0mkp0_cv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_keypoints_from_3dseg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkp0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\charles.fieseler\\documents\\current_work\\dlc_for_wbfm\\DLC_for_WBFM\\utils\\feature_detection\\utils_features.py\u001b[0m in \u001b[0;36mdetect_features_and_match\u001b[1;34m(im1, im2, max_features, matches_to_keep)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Match features.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mmatcher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDescriptorMatcher_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescriptors1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescriptors2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# Sort matches by score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.2) C:\\Miniconda3\\conda-bld\\opencv-suite_1534379934306\\work\\modules\\core\\src\\batch_distance.cpp:238: error: (-215:Assertion failed) type == src2.type() && src1.cols == src2.cols && (type == 5 || type == 0) in function 'cv::batchDistance'\n"
     ]
    }
   ],
   "source": [
    "all_matches, all_conf = track_neurons_full_video(btf_fname_red,\n",
    "                             start_frame=100,\n",
    "                             num_frames=10,\n",
    "                             num_slices=33,\n",
    "                             alpha=0.15,\n",
    "                             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\users\\charles.fieseler\\documents\\current_work\\dlc_for_wbfm\\dlc_for_wbfm\\utils\\feature_detection\\utils_features.py\u001b[0m(39)\u001b[0;36mdetect_features_and_match\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     37 \u001b[1;33m    \u001b[1;31m# Match features.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     38 \u001b[1;33m    \u001b[0mmatcher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDescriptorMatcher_create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 39 \u001b[1;33m    \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdescriptors1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescriptors2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     40 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     41 \u001b[1;33m    \u001b[1;31m# Sort matches by score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> len(keypoints1)\n",
      "4\n",
      "ipdb> len(keypoints2)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "%debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aside: timing tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video\n",
    "def open_tif(vid_fname):\n",
    "    with tifffile.TiffFile(vid_fname) as tif:\n",
    "        1+1\n",
    "\n",
    "def open_page(vid_fname):\n",
    "    with tifffile.TiffFile(vid_fname) as tif:\n",
    "        for i, page in enumerate(tif.pages):\n",
    "            dat = page.asarray()\n",
    "            if i>0:\n",
    "                break\n",
    "\n",
    "def open_volume(vid_fname, num_slices=33):\n",
    "    dat = []\n",
    "    with tifffile.TiffFile(vid_fname) as tif:\n",
    "        for i, page in enumerate(tif.pages):\n",
    "            dat.append(page.asarray())\n",
    "            if i>num_slices:\n",
    "                break\n",
    "                \n",
    "def open_with_imread(vid_fname, num_slices=33):\n",
    "    dat = tifffile.imread(vid_fname, key=range(num_slices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269 µs ± 4.12 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit open_tif(btf_fname_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ms ± 32.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit open_page(btf_fname_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.8 ms ± 3.79 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit open_volume(btf_fname_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.5 ms ± 4.02 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit open_with_imread(btf_fname_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:track_using_features] *",
   "language": "python",
   "name": "conda-env-track_using_features-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
