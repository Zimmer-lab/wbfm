{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incident-romania",
   "metadata": {},
   "source": [
    "# Build a motion model from feature matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-batch",
   "metadata": {},
   "source": [
    "## First, get keypoints\n",
    "\n",
    "Features and neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acute-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from DLC_for_WBFM.utils.feature_detection.utils_features import *\n",
    "from DLC_for_WBFM.utils.feature_detection.utils_tracklets import *\n",
    "from DLC_for_WBFM.utils.feature_detection.utils_detection import *\n",
    "from DLC_for_WBFM.utils.feature_detection.visualization_tracks import *\n",
    "from DLC_for_WBFM.utils.video_and_data_conversion.import_video_as_array import *\n",
    "from DLC_for_WBFM.utils.feature_detection.feature_pipeline import *\n",
    "from DLC_for_WBFM.utils.feature_detection.utils_affine import *\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "filled-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the 3d bigtiff folder\n",
    "bigtiff_folder = r'D:\\More-stabilized-wbfm'\n",
    "\n",
    "btf_fname_red = r'test2020-10-22_16-15-20_test4-channel-0-pco_camera1\\test2020-10-22_16-15-20_test4-channel-0-pco_camera1bigtiff.btf'\n",
    "btf_fname_red = os.path.join(bigtiff_folder, btf_fname_red)\n",
    "\n",
    "# Actually import\n",
    "import_opt = {'num_slices':33, 'alpha':0.15}\n",
    "\n",
    "dat0_vid = get_single_volume(btf_fname_red, 15, **import_opt)\n",
    "dat1_vid = get_single_volume(btf_fname_red, 30, **import_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitive-thousand",
   "metadata": {},
   "source": [
    "## Segment 2 volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "organizational-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\n",
      "[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\n",
      "[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\n",
      "[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\n",
      "[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\n",
      "[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\n",
      "[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\n",
      "[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\n"
     ]
    }
   ],
   "source": [
    "opt = {'num_slices':33, 'alpha':1.0}\n",
    "# Build point clouds for each plane\n",
    "all_keypoints_pcs0 = build_point_clouds_for_volume(dat0_vid, **import_opt)\n",
    "all_icp0 = build_correspondence_icp(all_keypoints_pcs0)\n",
    "\n",
    "all_keypoints_pcs1 = build_point_clouds_for_volume(dat0_vid, **import_opt)\n",
    "all_icp1 = build_correspondence_icp(all_keypoints_pcs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "optical-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_neurons = [k.points for k in all_keypoints_pcs0]\n",
    "all_matches = [m.correspondence_set for m in all_icp0]\n",
    "clust_df0 = build_tracklets_from_matches(all_neurons, all_matches)\n",
    "\n",
    "all_neurons = [k.points for k in all_keypoints_pcs1]\n",
    "all_matches = [m.correspondence_set for m in all_icp1]\n",
    "clust_df1 = build_tracklets_from_matches(all_neurons, all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "changed-service",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building pairwise correspondence...\n",
      "Building clusters...\n",
      "Finished ID'ing neurons\n",
      "Building pairwise correspondence...\n",
      "[Open3D WARNING] [KDTreeFlann::SetRawData] Failed due to no data.\n",
      "Building clusters...\n",
      "Finished ID'ing neurons\n",
      "Removed the following duplicates: [106, 105, 104, 97, 93, 83, 82, 78, 73, 70, 69, 67, 64, 62, 61, 51, 44, 35, 32, 31, 29, 28, 21, 15, 9]\n"
     ]
    }
   ],
   "source": [
    "opt = {'num_slices':33, 'alpha':1.0, 'verbose':1}\n",
    "neurons0, df0, icp0, pcs0 = detect_neurons_using_ICP(dat0_vid, **opt)\n",
    "neurons1, df1, icp1, pcs1 = detect_neurons_using_ICP(dat1_vid, **opt)\n",
    "\n",
    "all_features0, all_features1, kp0, kp1, feature_matches = build_features_and_match_2volumes(dat0_vid,dat1_vid,\n",
    "                                                                      verbose=1,\n",
    "                                                                      matches_to_keep=0.8,\n",
    "                                                                      num_features_per_plane=10000,\n",
    "                                                                      detect_keypoints=True,\n",
    "                                                                      kp0=neurons0,\n",
    "                                                                      kp1=neurons1)\n",
    "\n",
    "all_matches, f2n, all_conf = match_centroids_using_tree(np.array(neurons0), \n",
    "                               np.array(neurons1), \n",
    "                               all_features0, \n",
    "                               all_features1,\n",
    "                               radius=8,\n",
    "                               max_nn=50,\n",
    "                               min_features_needed=5,\n",
    "                                   verbose=1,\n",
    "                                     to_mirror=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-yorkshire",
   "metadata": {},
   "source": [
    "## Alternate way of getting keypoints: my Frame class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "seven-leadership",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:44<00:00, 11.07s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:09<00:00,  2.41s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:14<00:00, 14.62s/it]\n"
     ]
    }
   ],
   "source": [
    "opt = {'start_frame':0,\n",
    "       'num_frames':5,\n",
    "      'num_reference_frames':4,\n",
    "      'start_slice':4}\n",
    "all_matches, all_other_frames, reference_set = track_via_reference_frames(btf_fname_red, **opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "comparative-small",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================\n",
      "                ReferenceFrame:\n",
      "                Frame index: 0 \n",
      "                Number of neurons: 202 \n",
      "\n",
      "=======================================\n",
      "                ReferenceFrame:\n",
      "                Frame index: 1 \n",
      "                Number of neurons: 187 \n",
      "\n",
      "=======================================\n",
      "                RegisteredReferenceFrames:\n",
      "                Number of frames: 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reference_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-collective",
   "metadata": {},
   "source": [
    "## An example of a full affine model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "historic-vaccine",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts0_unmatched = reference_set.reference_frames[0].keypoint_locs\n",
    "pts1_unmatched = reference_set.reference_frames[1].keypoint_locs\n",
    "\n",
    "feature_matches = reference_set.feature_matches[(0,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "inside-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align the keypoints via matches\n",
    "\n",
    "pts0 = np.zeros((len(feature_matches), 3), dtype=np.float32)\n",
    "pts1 = np.zeros((len(feature_matches), 3), dtype=np.float32)\n",
    "for m, match in enumerate(feature_matches):\n",
    "    pts0[m, :] = pts0_unmatched[match.queryIdx]\n",
    "    pts1[m, :] = pts1_unmatched[match.trainIdx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "complicated-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h = np.transpose(h)\n",
    "# Note: neurons0 is a dataframe\n",
    "# n0_2d = np.array([np.array([n[1], n[2]]) for n in neurons0])\n",
    "\n",
    "val, h, inliers = cv2.estimateAffine3D(pts0,pts1, confidence=0.99)\n",
    "pts0_trans = cv2.transform(np.array([pts0]), h)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "economic-toilet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.15033187e-01, -2.96604776e-02, -2.51493568e-03,\n",
       "         1.07420336e+01],\n",
       "       [-1.99451570e-01,  8.03839099e-01, -6.27004957e-01,\n",
       "         2.64056234e+02],\n",
       "       [-1.46517814e-01,  5.14687677e-01,  7.89790389e-01,\n",
       "        -1.47872252e+02]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "charming-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make point clouds\n",
    "pc0 = o3d.geometry.PointCloud()\n",
    "pc0.points = o3d.utility.Vector3dVector(pts0)\n",
    "pc0.paint_uniform_color([0,0,0])\n",
    "\n",
    "pc0_trans = o3d.geometry.PointCloud()\n",
    "pc0_trans.points = o3d.utility.Vector3dVector(pts0_trans)\n",
    "pc0_trans.paint_uniform_color([0.5,0.5,0.5])\n",
    "\n",
    "pc1 = o3d.geometry.PointCloud()\n",
    "pc1.points = o3d.utility.Vector3dVector(pts1)\n",
    "pc1.paint_uniform_color([1,0,0])\n",
    "\n",
    "o3d.visualization.draw_geometries([pc0,pc0_trans, pc1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-assignment",
   "metadata": {},
   "source": [
    "## Next, use the affine model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aboriginal-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "i0, i1 = 0, 1\n",
    "\n",
    "f0 = reference_set.reference_frames[i0]\n",
    "f1 = reference_set.reference_frames[i1]\n",
    "all_feature_matches = reference_set.feature_matches[(i0, i1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "worldwide-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 202/202 [00:04<00:00, 42.01it/s]\n"
     ]
    }
   ],
   "source": [
    "all_lines = None\n",
    "all_trans = None\n",
    "\n",
    "for which_neuron in tqdm(range(len(f0.neuron_locs))):\n",
    "    success, neuron0_trans = propagate_via_affine_model(which_neuron, f0, f1, all_feature_matches)\n",
    "    if not success:\n",
    "        continue\n",
    "    pc0_neuron, pc1_trans, pc1_neuron, line = create_affine_visualizations(which_neuron, f0, f1, neuron0_trans)\n",
    "\n",
    "    if all_lines is None:\n",
    "        all_lines = line\n",
    "        all_trans = pc1_trans\n",
    "    else:\n",
    "        all_lines = all_lines + line\n",
    "        all_trans = all_trans + pc1_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "wound-accreditation",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pc0_neuron, all_trans, pc1_neuron, all_lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-strip",
   "metadata": {},
   "source": [
    "# Finally, turn this into a set of matches\n",
    "\n",
    "There are three obvious forms of mismatch:\n",
    "1. Missing neuron in either v0 or v1\n",
    "2. Related, multiple v0 neurons near one v1 neuron\n",
    "3. Neuron pushed to an ambiguous location, not very close to a single v1 neuron\n",
    "\n",
    "To some extent this just needs better neuron segmentation. However, the features are what they are; theoretically the v0 neurons should be pushed close to a v1 neuron, even if it is missing\n",
    "\n",
    "Strategy 1: greedy\n",
    "1. Loop over v1 neurons, taking the closest one\n",
    "\n",
    "--- FOR NOW DO THIS:\n",
    "\n",
    "Strategy 1.5: greedy with best of 2\n",
    "1. Loop over v1 neurons, taking the closest two\n",
    "2. If the closest one is significantly closer, only keep that one\n",
    "\n",
    "\n",
    "Strategy 2: bipartite\n",
    "1. Loop over v0 or v1 neurons, getting distances to ~2 closest neighbors\n",
    "2. Bipartite matching on resulting graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "martial-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tree to query v1 neurons\n",
    "tree_n1 = o3d.geometry.KDTreeFlann(pc1_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "wireless-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over locations of pushed v0 neurons\n",
    "all_matches = [] # Without confidence\n",
    "all_conf = []\n",
    "nn_opt = { 'radius':20.0, 'max_nn':2}\n",
    "verbose = 1\n",
    "dist_ratio = 1.5\n",
    "conf_func = lambda dist : 1.0 / (dist/10+1.0)\n",
    "for i, neuron in enumerate(np.array(all_trans.points)):\n",
    "    [k, two_neighbors, two_dist] = tree_n1.search_hybrid_vector_3d(neuron, **nn_opt)\n",
    "    \n",
    "    if k==0:\n",
    "#         print(f\"No close neuron {i}\")\n",
    "        continue\n",
    "    \n",
    "    if k==1:\n",
    "        dist = two_dist[0]\n",
    "        i_match = two_neighbors[0]\n",
    "    else:\n",
    "        if two_dist[0]/two_dist[1] > dist_ratio:\n",
    "            dist = two_dist[1]\n",
    "            i_match = two_neighbors[1]\n",
    "        elif two_dist[1]/two_dist[0] > dist_ratio:\n",
    "            dist = two_dist[1]\n",
    "            i_match = two_neighbors[1]\n",
    "        else:\n",
    "            if verbose >= 2:\n",
    "                print(f\"Neuron {i} has two close neighbors\")\n",
    "            continue\n",
    "    \n",
    "    if verbose >= 2:\n",
    "        print(f\"Found good match for neuron {i}\")\n",
    "    all_matches.append([i, i_match])\n",
    "    all_conf.append(conf_func(dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-reasoning",
   "metadata": {},
   "source": [
    "# Full video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-rogers",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████████████████████████████████▌                | 394/499 [1:37:15<23:44, 13.57s/it]"
     ]
    }
   ],
   "source": [
    "# Now, full fv\n",
    "out = track_neurons_full_video(btf_fname_red,\n",
    "                             start_frame=0,\n",
    "                             num_frames=500,\n",
    "                             num_slices=33,\n",
    "                             alpha=0.15,\n",
    "                             neuron_feature_radius=5.0,\n",
    "                             do_mini_max_projections=True,\n",
    "                             use_affine_matching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matches, all_conf, all_neurons = out\n",
    "clust_df = build_tracklets_from_matches(all_neurons, all_matches, all_conf, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "fname = 'clust_df_dat_affine.pickle'\n",
    "with open(fname, 'wb') as f:\n",
    "    pickle.dump(clust_df,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-shield",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:track_using_features] *",
   "language": "python",
   "name": "conda-env-track_using_features-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
